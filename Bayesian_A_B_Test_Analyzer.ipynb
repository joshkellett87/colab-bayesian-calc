{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshkellett87/colab-bayesian-calc/blob/main/Bayesian_A_B_Test_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Test Calculator for Online Experiments ðŸ“ˆ\n",
        "Robust a/b/n test calculator created by Josh Kellett.\n",
        "\n",
        "**Instructions**\n",
        "1.   Go to Runtime > Run All to start calc\n",
        "2.   Enter # of test variants\n",
        "3.   Enter priors and set power for control + variants\n",
        "4.   Choose ROPE\n",
        "5.   Add sample & conversion counts for all versions\n",
        "\n",
        "That's it! From there you'll get a detailed analysis of your test results, including decision recommendations and a full set of charts."
      ],
      "metadata": {
        "id": "JQVr_MRgLUmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# --- Boilerplate Imports & Setup for Tall Output ---\n",
        "#\n",
        "import sys\n",
        "from io import StringIO\n",
        "from IPython.display import HTML, display\n",
        "import html\n",
        "\n",
        "# Store the original standard output\n",
        "_original_stdout = sys.stdout\n",
        "# Create a StringIO object to capture output in memory\n",
        "_captured_output = StringIO()\n",
        "# Redirect standard output to our StringIO object\n",
        "# This needs to happen before any libraries (like rich.Console) that might cache sys.stdout are initialized\n",
        "# or before any print statements that need to be captured.\n",
        "sys.stdout = _captured_output\n",
        "# --- End of output capturing setup ---\n",
        "#\n",
        "\n",
        "# --- User's Original Imports ---\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from rich.console import Console # Will now write to the redirected sys.stdout\n",
        "from rich.table import Table\n",
        "from rich.panel import Panel\n",
        "from rich.text import Text\n",
        "from rich.padding import Padding\n",
        "from rich.style import Style # Included as it was in the user's script\n",
        "\n",
        "# v=======================================================================v\n",
        "# |                                                                       |\n",
        "# |   USER'S FULL SCRIPT CONTENT STARTS HERE (CLASSES, FUNCTIONS, MAIN)   |\n",
        "# |                                                                       |\n",
        "# v=======================================================================v\n",
        "\n",
        "# Helper function to calculate Highest Density Interval (HDI)\n",
        "def _calculate_hdi(samples, credible_mass=0.95):\n",
        "    \"\"\"Calculate the Highest Density Interval (HDI) for a list of samples.\"\"\"\n",
        "    if samples is None or len(samples) == 0:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    samples = samples[~np.isnan(samples)]\n",
        "    if len(samples) == 0:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    sorted_samples = np.sort(samples)\n",
        "    n_samples = len(samples)\n",
        "\n",
        "    interval_idx_inc = int(np.floor(credible_mass * n_samples))\n",
        "    if interval_idx_inc == 0:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    n_intervals = n_samples - interval_idx_inc\n",
        "    if n_intervals <= 0:\n",
        "         return (sorted_samples[0], sorted_samples[-1])\n",
        "\n",
        "    interval_width = sorted_samples[interval_idx_inc:] - sorted_samples[:n_intervals]\n",
        "\n",
        "    if len(interval_width) == 0:\n",
        "        return (sorted_samples[0], sorted_samples[-1])\n",
        "\n",
        "    min_idx = np.argmin(interval_width)\n",
        "    hdi_min = sorted_samples[min_idx]\n",
        "    hdi_max = sorted_samples[min_idx + interval_idx_inc]\n",
        "    return hdi_min, hdi_max\n",
        "\n",
        "class BayesianExperiment:\n",
        "    \"\"\"\n",
        "    A class to perform Bayesian analysis for an A/B test with binomial data,\n",
        "    supporting multiple solution variants.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_solution_variants=1):\n",
        "        if not isinstance(num_solution_variants, int) or num_solution_variants < 1:\n",
        "            raise ValueError(\"Number of solution variants must be a positive integer.\")\n",
        "        self.num_solution_variants = num_solution_variants\n",
        "\n",
        "        # Control parameters\n",
        "        self.control_prior_alpha = 1.0\n",
        "        self.control_prior_beta = 1.0\n",
        "        self.control_posterior_alpha = 1.0\n",
        "        self.control_posterior_beta = 1.0\n",
        "        self.control_samples = 0\n",
        "        self.control_conversions = 0\n",
        "        self.control_observed_alpha_likelihood = 1\n",
        "        self.control_observed_beta_likelihood = 1\n",
        "\n",
        "        # Solution variant parameters (lists)\n",
        "        self.solution_prior_alpha = [1.0] * num_solution_variants\n",
        "        self.solution_prior_beta = [1.0] * num_solution_variants\n",
        "        self.solution_posterior_alpha = [1.0] * num_solution_variants\n",
        "        self.solution_posterior_beta = [1.0] * num_solution_variants\n",
        "        self.solution_samples = [0] * num_solution_variants\n",
        "        self.solution_conversions = [0] * num_solution_variants\n",
        "        self.solution_observed_alpha_likelihood = [1] * num_solution_variants\n",
        "        self.solution_observed_beta_likelihood = [1] * num_solution_variants\n",
        "\n",
        "        self.variant_names = [\"Control\"] + [f\"Solution {i+1}\" for i in range(num_solution_variants)]\n",
        "\n",
        "\n",
        "    def set_priors(self, control_alpha, control_beta, solution_alphas, solution_betas):\n",
        "        if control_alpha <= 0 or control_beta <= 0:\n",
        "            raise ValueError(\"Control prior alpha and beta parameters must be positive.\")\n",
        "        if not (isinstance(solution_alphas, list) and isinstance(solution_betas, list) and\n",
        "                len(solution_alphas) == self.num_solution_variants and len(solution_betas) == self.num_solution_variants):\n",
        "            raise ValueError(f\"Solution priors must be lists of length {self.num_solution_variants}.\")\n",
        "        for sa, sb in zip(solution_alphas, solution_betas):\n",
        "            if sa <= 0 or sb <= 0:\n",
        "                raise ValueError(\"Solution prior alpha and beta parameters must be positive.\")\n",
        "\n",
        "        self.control_prior_alpha = control_alpha\n",
        "        self.control_prior_beta = control_beta\n",
        "        self.control_posterior_alpha = control_alpha\n",
        "        self.control_posterior_beta = control_beta\n",
        "\n",
        "        self.solution_prior_alpha = list(solution_alphas)\n",
        "        self.solution_prior_beta = list(solution_betas)\n",
        "        self.solution_posterior_alpha = list(solution_alphas)\n",
        "        self.solution_posterior_beta = list(solution_betas)\n",
        "\n",
        "\n",
        "    def update_results(self, control_samples, control_conversions, solution_samples_list, solution_conversions_list):\n",
        "        if control_samples < control_conversions or control_samples < 0:\n",
        "            raise ValueError(\"Control samples must be non-negative and >= control conversions.\")\n",
        "        if not (isinstance(solution_samples_list, list) and isinstance(solution_conversions_list, list) and\n",
        "                len(solution_samples_list) == self.num_solution_variants and len(solution_conversions_list) == self.num_solution_variants):\n",
        "            raise ValueError(f\"Solution results must be lists of length {self.num_solution_variants}.\")\n",
        "\n",
        "        self.control_samples = control_samples\n",
        "        self.control_conversions = control_conversions\n",
        "        control_losses = control_samples - control_conversions\n",
        "        self.control_posterior_alpha = self.control_prior_alpha + control_conversions\n",
        "        self.control_posterior_beta = self.control_prior_beta + control_losses\n",
        "        self.control_observed_alpha_likelihood = control_conversions + (1 if control_conversions == 0 and control_losses == 0 else 0)\n",
        "        self.control_observed_beta_likelihood = control_losses + (1 if control_conversions == 0 and control_losses == 0 else 0)\n",
        "\n",
        "        for i in range(self.num_solution_variants):\n",
        "            s_samples = solution_samples_list[i]\n",
        "            s_conversions = solution_conversions_list[i]\n",
        "            if s_samples < s_conversions or s_samples < 0:\n",
        "                raise ValueError(f\"Solution {i+1} samples must be non-negative and >= conversions.\")\n",
        "            if s_conversions < 0:\n",
        "                raise ValueError(f\"Solution {i+1} conversions must be non-negative.\")\n",
        "\n",
        "            self.solution_samples[i] = s_samples\n",
        "            self.solution_conversions[i] = s_conversions\n",
        "            s_losses = s_samples - s_conversions\n",
        "            self.solution_posterior_alpha[i] = self.solution_prior_alpha[i] + s_conversions\n",
        "            self.solution_posterior_beta[i] = self.solution_prior_beta[i] + s_losses\n",
        "            self.solution_observed_alpha_likelihood[i] = s_conversions + (1 if s_conversions == 0 and s_losses == 0 else 0)\n",
        "            self.solution_observed_beta_likelihood[i] = s_losses + (1 if s_conversions == 0 and s_losses == 0 else 0)\n",
        "\n",
        "\n",
        "    def get_posterior_samples(self, n_samples=20000):\n",
        "        \"\"\"Generates posterior samples for control and all solution variants.\"\"\"\n",
        "        all_samples = {}\n",
        "        all_samples['control_rate'] = stats.beta.rvs(\n",
        "            self.control_posterior_alpha, self.control_posterior_beta, size=n_samples\n",
        "        )\n",
        "        for i in range(self.num_solution_variants):\n",
        "            variant_name = f\"solution_{i+1}_rate\"\n",
        "            all_samples[variant_name] = stats.beta.rvs(\n",
        "                self.solution_posterior_alpha[i], self.solution_posterior_beta[i], size=n_samples\n",
        "            )\n",
        "\n",
        "        for i in range(self.num_solution_variants):\n",
        "            all_samples[f\"abs_diff_s{i+1}_c\"] = all_samples[f\"solution_{i+1}_rate\"] - all_samples['control_rate']\n",
        "\n",
        "        for i in range(self.num_solution_variants):\n",
        "            rel_lift_samples = np.full_like(all_samples['control_rate'], np.nan)\n",
        "            valid_mask = all_samples['control_rate'] > 1e-9\n",
        "            rel_lift_samples[valid_mask] = (all_samples[f\"solution_{i+1}_rate\"][valid_mask] - all_samples['control_rate'][valid_mask]) / all_samples['control_rate'][valid_mask]\n",
        "            all_samples[f\"rel_lift_s{i+1}_c\"] = rel_lift_samples\n",
        "\n",
        "        return all_samples\n",
        "\n",
        "    def calculate_metrics(self, rope_abs_diff=(-0.005, 0.005), rope_rel_lift=(-0.05, 0.05),\n",
        "                          prob_beat_threshold=0.0, credible_mass=0.95, n_samples_for_calc=20000):\n",
        "        \"\"\"Calculates metrics for control and all solution variants.\"\"\"\n",
        "        samples = self.get_posterior_samples(n_samples=n_samples_for_calc)\n",
        "        metrics = {'control': {}, 'solutions': [{} for _ in range(self.num_solution_variants)]}\n",
        "\n",
        "        control_s = samples['control_rate']\n",
        "        metrics['control']['posterior_mean_rate'] = np.mean(control_s)\n",
        "        metrics['control']['rate_hdi'] = _calculate_hdi(control_s, credible_mass)\n",
        "\n",
        "        all_variant_samples = [samples['control_rate']]\n",
        "        for i in range(self.num_solution_variants):\n",
        "            sol_s = samples[f\"solution_{i+1}_rate\"]\n",
        "            abs_diff_s = samples[f\"abs_diff_s{i+1}_c\"]\n",
        "            rel_lift_s = samples[f\"rel_lift_s{i+1}_c\"][~np.isnan(samples[f\"rel_lift_s{i+1}_c\"])]\n",
        "\n",
        "            metrics['solutions'][i]['name'] = f\"Solution {i+1}\"\n",
        "            metrics['solutions'][i]['posterior_mean_rate'] = np.mean(sol_s)\n",
        "            metrics['solutions'][i]['rate_hdi'] = _calculate_hdi(sol_s, credible_mass)\n",
        "\n",
        "            metrics['solutions'][i]['absolute_difference_mean'] = np.mean(abs_diff_s)\n",
        "            metrics['solutions'][i]['absolute_difference_hdi'] = _calculate_hdi(abs_diff_s, credible_mass)\n",
        "\n",
        "            if len(rel_lift_s) > 0:\n",
        "                metrics['solutions'][i]['relative_lift_mean'] = np.mean(rel_lift_s)\n",
        "                metrics['solutions'][i]['relative_lift_hdi'] = _calculate_hdi(rel_lift_s, credible_mass)\n",
        "            else:\n",
        "                metrics['solutions'][i]['relative_lift_mean'] = np.nan\n",
        "                metrics['solutions'][i]['relative_lift_hdi'] = (np.nan, np.nan)\n",
        "\n",
        "            metrics['solutions'][i]['prob_beats_control'] = np.mean(sol_s > control_s)\n",
        "            metrics['solutions'][i]['prob_beats_control_by_threshold'] = np.mean(sol_s > (control_s + prob_beat_threshold))\n",
        "\n",
        "            metrics['solutions'][i]['prob_abs_diff_below_rope'] = np.mean(abs_diff_s < rope_abs_diff[0])\n",
        "            metrics['solutions'][i]['prob_abs_diff_in_rope'] = np.mean((abs_diff_s >= rope_abs_diff[0]) & (abs_diff_s <= rope_abs_diff[1]))\n",
        "            metrics['solutions'][i]['prob_abs_diff_above_rope'] = np.mean(abs_diff_s > rope_abs_diff[1])\n",
        "\n",
        "            if len(rel_lift_s) > 0:\n",
        "                metrics['solutions'][i]['prob_rel_lift_below_rope'] = np.mean(rel_lift_s < rope_rel_lift[0])\n",
        "                metrics['solutions'][i]['prob_rel_lift_in_rope'] = np.mean((rel_lift_s >= rope_rel_lift[0]) & (rel_lift_s <= rope_rel_lift[1]))\n",
        "                metrics['solutions'][i]['prob_rel_lift_above_rope'] = np.mean(rel_lift_s > rope_rel_lift[1])\n",
        "            else:\n",
        "                for key in ['prob_rel_lift_below_rope', 'prob_rel_lift_in_rope', 'prob_rel_lift_above_rope']:\n",
        "                    metrics['solutions'][i][key] = np.nan\n",
        "\n",
        "            metrics['solutions'][i]['expected_loss_vs_control_choosing_solution'] = np.mean(np.maximum(0, control_s - sol_s))\n",
        "            metrics['solutions'][i]['expected_loss_vs_control_choosing_control'] = np.mean(np.maximum(0, sol_s - control_s))\n",
        "\n",
        "            all_variant_samples.append(sol_s)\n",
        "\n",
        "        stacked_samples = np.stack(all_variant_samples, axis=-1)\n",
        "        best_variant_indices = np.argmax(stacked_samples, axis=1)\n",
        "\n",
        "        metrics['prob_control_is_best'] = np.mean(best_variant_indices == 0)\n",
        "        for i in range(self.num_solution_variants):\n",
        "            metrics['solutions'][i]['prob_is_best'] = np.mean(best_variant_indices == (i + 1))\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def get_decision_summary(self, metrics, rope_abs_diff_vs_control, p_threshold=0.95, loss_ratio_threshold=5):\n",
        "        \"\"\"Generates a nuanced decision summary for multiple variants.\"\"\"\n",
        "        best_overall_prob = metrics.get('prob_control_is_best', 0.0)\n",
        "        best_variant_idx = -1\n",
        "\n",
        "        for i, sol_metrics in enumerate(metrics['solutions']):\n",
        "            if sol_metrics.get('prob_is_best', 0.0) > best_overall_prob:\n",
        "                best_overall_prob = sol_metrics.get('prob_is_best', 0.0)\n",
        "                best_variant_idx = i\n",
        "\n",
        "        # Case 1: Control is most likely the best\n",
        "        if best_variant_idx == -1:\n",
        "            evaluation = f\"Control is Most Likely Best (P(Best)={metrics.get('prob_control_is_best', 0.0):.1%})\"\n",
        "            recommendation = \"Stick with Control.\"\n",
        "            rec_style = \"blue\"\n",
        "            # Check if any solution offers a compelling reason to consider despite Control leading\n",
        "            for i, sol_metrics in enumerate(metrics['solutions']):\n",
        "                 prob_s_beats_c_by_thresh = sol_metrics.get('prob_beats_control_by_threshold', 0.0)\n",
        "                 loss_ctrl_vs_sol = sol_metrics.get('expected_loss_vs_control_choosing_control', np.inf)\n",
        "                 loss_sol_vs_ctrl = sol_metrics.get('expected_loss_vs_control_choosing_solution', np.inf)\n",
        "                 # If a solution has high P(>Ctrl+Thresh) and significantly lower risk if chosen\n",
        "                 if prob_s_beats_c_by_thresh > p_threshold and loss_ctrl_vs_sol > (loss_sol_vs_ctrl * loss_ratio_threshold / 2): # Halved threshold for more sensitivity\n",
        "                      recommendation += f\" However, Solution {i+1} shows strong potential (high P(>{metrics.get('prob_beat_threshold_value',0.0):.1%}) & favorable risk) and could be considered if Control's lead is marginal.\"\n",
        "                      rec_style = \"yellow\" # Change style if such a solution exists\n",
        "                      break\n",
        "            return evaluation, recommendation, rec_style\n",
        "\n",
        "        # Case 2: A Solution variant is most likely the best\n",
        "        best_sol_metrics = metrics['solutions'][best_variant_idx]\n",
        "        sol_name = best_sol_metrics['name'] # e.g. \"Solution 1\"\n",
        "        prob_best_sol_val = best_sol_metrics.get('prob_is_best', 0.0)\n",
        "        evaluation = f\"{sol_name} is Most Likely Best (P(Best)={prob_best_sol_val:.1%})\"\n",
        "\n",
        "        hdi_low, hdi_high = best_sol_metrics.get('absolute_difference_hdi', (np.nan, np.nan))\n",
        "        rope_low, rope_high = rope_abs_diff_vs_control\n",
        "\n",
        "        loss_ctrl_vs_sol = best_sol_metrics.get('expected_loss_vs_control_choosing_control', np.inf)\n",
        "        loss_sol_vs_ctrl = best_sol_metrics.get('expected_loss_vs_control_choosing_solution', np.inf)\n",
        "\n",
        "        if np.isnan(hdi_low) or np.isnan(hdi_high):\n",
        "            return evaluation, f\"Error calculating HDI for {sol_name}. Cannot provide detailed recommendation.\", \"red\"\n",
        "\n",
        "        # Define helper conditions for clarity\n",
        "        is_favorable_risk = loss_ctrl_vs_sol > (loss_sol_vs_ctrl * loss_ratio_threshold)\n",
        "\n",
        "        # The p_threshold (e.g. 0.95) is for the probability of beating control *by the specified threshold*\n",
        "        # The actual threshold value (e.g., 0.1% uplift) is stored in metrics['prob_beat_threshold_value']\n",
        "        user_uplift_threshold_val = metrics.get('prob_beat_threshold_value', 0.0)\n",
        "        prob_sol_beats_ctrl_by_user_thresh_val = best_sol_metrics.get('prob_beats_control_by_threshold', 0.0)\n",
        "        is_highly_likely_to_beat_ctrl_by_thresh = prob_sol_beats_ctrl_by_user_thresh_val >= p_threshold\n",
        "        threshold_text = f\"Control + {user_uplift_threshold_val:.1%}\" if user_uplift_threshold_val > 0 else \"Control\"\n",
        "\n",
        "\n",
        "        # Sub-case 2.1: Clear win (HDI for difference entirely above ROPE)\n",
        "        if hdi_low > rope_high:\n",
        "            recommendation = f\"Strongly recommend {sol_name}. Clear win vs Control (95% HDI for difference is entirely above ROPE).\"\n",
        "            rec_style = \"green\"\n",
        "        # Sub-case 2.2: Clear loss (HDI for difference entirely below ROPE)\n",
        "        elif hdi_high < rope_low:\n",
        "            recommendation = f\"Reject {sol_name}. Likely worse vs Control (95% HDI for difference is entirely below ROPE).\"\n",
        "            rec_style = \"red\"\n",
        "        # Sub-case 2.3: Practically Equivalent (HDI for difference entirely within ROPE)\n",
        "        elif hdi_low >= rope_low and hdi_high <= rope_high:\n",
        "            if is_highly_likely_to_beat_ctrl_by_thresh and is_favorable_risk:\n",
        "                 recommendation = f\"Consider {sol_name}. Practically equivalent to Control (difference within ROPE), but P(>{threshold_text}) is high & risk profile is favorable.\"\n",
        "                 rec_style = \"yellow\"\n",
        "            elif prob_best_sol_val > 0.75 and is_favorable_risk:\n",
        "                 recommendation = f\"Consider {sol_name}. Practically equivalent to Control (difference within ROPE), but P(Best) is high & risk profile is favorable.\"\n",
        "                 rec_style = \"yellow\"\n",
        "            else:\n",
        "                recommendation = f\"{sol_name} is likely best but practically equivalent to Control (difference within ROPE).\"\n",
        "                rec_style = \"blue\"\n",
        "        # Sub-case 2.4: Nuanced (HDI overlaps ROPE - this is the main area for tiered logic)\n",
        "        else:\n",
        "            if prob_best_sol_val >= 0.90:\n",
        "                if is_favorable_risk or is_highly_likely_to_beat_ctrl_by_thresh:\n",
        "                    recommendation = f\"Strongly recommend {sol_name} (P(Best)={prob_best_sol_val:.1%}). Strong evidence and favorable risk/reward profile vs Control.\"\n",
        "                    rec_style = \"green\"\n",
        "                else:\n",
        "                    recommendation = f\"{sol_name} is very likely best (P(Best)={prob_best_sol_val:.1%}). Consider accepting vs Control.\"\n",
        "                    rec_style = \"yellow\"\n",
        "            elif prob_best_sol_val >= 0.75:\n",
        "                if is_favorable_risk or is_highly_likely_to_beat_ctrl_by_thresh:\n",
        "                    recommendation = f\"{sol_name} is a strong candidate (P(Best)={prob_best_sol_val:.1%}). Good evidence and risk profile vs Control.\"\n",
        "                    rec_style = \"green\"\n",
        "                else:\n",
        "                    recommendation = f\"{sol_name} shows good promise (P(Best)={prob_best_sol_val:.1%}). Worth considering vs Control.\"\n",
        "                    rec_style = \"yellow\"\n",
        "            elif prob_best_sol_val >= 0.60:\n",
        "                if is_favorable_risk and is_highly_likely_to_beat_ctrl_by_thresh:\n",
        "                     recommendation = f\"{sol_name} shows potential (P(Best)={prob_best_sol_val:.1%}). Risk/reward vs Control may be favorable.\"\n",
        "                     rec_style = \"yellow\"\n",
        "                elif is_favorable_risk or is_highly_likely_to_beat_ctrl_by_thresh:\n",
        "                     recommendation = f\"{sol_name} has some potential (P(Best)={prob_best_sol_val:.1%}). Evaluate risk/reward vs Control carefully.\"\n",
        "                     rec_style = \"yellow\"\n",
        "                else:\n",
        "                    recommendation = f\"{sol_name} is marginally ahead (P(Best)={prob_best_sol_val:.1%}). Decision vs Control requires careful consideration of other factors.\"\n",
        "                    rec_style = \"blue\"\n",
        "            else: # P(Best Sol) < 0.60\n",
        "                recommendation = f\"Evidence for {sol_name} is not conclusive (P(Best)={prob_best_sol_val:.1%}). Control remains a strong contender. Consider gathering more data if feasible.\"\n",
        "                rec_style = \"blue\"\n",
        "\n",
        "        return evaluation, recommendation, rec_style\n",
        "\n",
        "    def _get_dynamic_axis_range(self, *distributions_params_or_samples,\n",
        "                                percentile_low=0.01, percentile_high=99.99,\n",
        "                                padding_factor=0.08, allow_negative=False):\n",
        "        all_quantiles = np.array([])\n",
        "        for item in distributions_params_or_samples:\n",
        "            if item is None: continue\n",
        "            if isinstance(item, tuple) and len(item) == 2:\n",
        "                alpha, beta = item\n",
        "                if alpha > 0 and beta > 0:\n",
        "                    q_low = stats.beta.ppf(percentile_low / 100.0, alpha, beta)\n",
        "                    q_high = stats.beta.ppf(percentile_high / 100.0, alpha, beta)\n",
        "                    if not np.isnan(q_low) and not np.isnan(q_high):\n",
        "                         all_quantiles = np.concatenate([all_quantiles, [q_low, q_high]])\n",
        "            elif isinstance(item, np.ndarray) and item.size > 0:\n",
        "                valid_samples = item[~np.isnan(item)]\n",
        "                if valid_samples.size > 0:\n",
        "                    q_low = np.percentile(valid_samples, percentile_low)\n",
        "                    q_high = np.percentile(valid_samples, percentile_high)\n",
        "                    all_quantiles = np.concatenate([all_quantiles, [q_low, q_high]])\n",
        "        if all_quantiles.size == 0:\n",
        "            return (0.0, 0.1) if not allow_negative else (-0.05, 0.05)\n",
        "        min_val = np.min(all_quantiles)\n",
        "        max_val = np.max(all_quantiles)\n",
        "        current_range = max_val - min_val\n",
        "        if current_range < 1e-6:\n",
        "            padding = 0.005\n",
        "        else:\n",
        "            padding = current_range * padding_factor\n",
        "        axis_min = min_val - padding\n",
        "        if not allow_negative:\n",
        "            axis_min = max(0.0, axis_min)\n",
        "        axis_max = max_val + padding\n",
        "        if not allow_negative:\n",
        "             axis_max = min(1.0, axis_max)\n",
        "        if axis_max <= axis_min:\n",
        "             axis_max = axis_min + (0.001 if not allow_negative else 0.0001 * abs(axis_min) + 0.0001)\n",
        "        if not allow_negative and axis_max > 1.0: axis_max = 1.0\n",
        "        if not allow_negative and axis_min < 0.0: axis_min = 0.0\n",
        "        return axis_min, axis_max\n",
        "\n",
        "\n",
        "    def plot_distributions_plotly(self, rope_abs_diff=(-0.005, 0.005), rope_rel_lift=(-0.05, 0.05),\n",
        "                                  n_samples_for_plot=10000, solution_to_compare_idx=None): # Added solution_to_compare_idx\n",
        "        \"\"\"\n",
        "        Generate and display interactive plots for multiple variants.\n",
        "        Note: Plotly fig.show() renders directly to Colab output, not captured in the tall text box.\n",
        "        \"\"\"\n",
        "        samples_data = self.get_posterior_samples(n_samples=n_samples_for_plot)\n",
        "        control_post_s = samples_data['control_rate']\n",
        "\n",
        "        solution_line_colors = ['lightcoral', 'lightseagreen', 'mediumpurple', 'gold']\n",
        "        solution_fill_colors = [\n",
        "            'rgba(240,128,128,0.4)',\n",
        "            'rgba(32,178,170,0.4)',\n",
        "            'rgba(147,112,219,0.4)',\n",
        "            'rgba(255,215,0,0.4)'\n",
        "        ]\n",
        "\n",
        "        metrics_temp = self.calculate_metrics(rope_abs_diff, rope_rel_lift)\n",
        "        best_sol_idx_for_plot = -1\n",
        "        max_p_best = metrics_temp.get('prob_control_is_best', 0.0)\n",
        "        best_sol_name_for_title = \"Solution 1\"\n",
        "        if self.num_solution_variants > 0:\n",
        "            # Ensure there's at least one solution to avoid index error if num_solution_variants is 0\n",
        "            if metrics_temp['solutions']:\n",
        "                best_sol_name_for_title = metrics_temp['solutions'][0]['name']\n",
        "\n",
        "        for i, sol_metrics in enumerate(metrics_temp['solutions']):\n",
        "            if sol_metrics.get('prob_is_best', 0.0) > max_p_best:\n",
        "                max_p_best = sol_metrics.get('prob_is_best', 0.0)\n",
        "                best_sol_idx_for_plot = i\n",
        "                best_sol_name_for_title = sol_metrics['name']\n",
        "\n",
        "        # Override with user selection if provided\n",
        "        if solution_to_compare_idx is not None and 0 <= solution_to_compare_idx < self.num_solution_variants:\n",
        "            best_sol_idx_for_plot = solution_to_compare_idx\n",
        "            best_sol_name_for_title = f\"Solution {best_sol_idx_for_plot + 1}\"\n",
        "        elif solution_to_compare_idx is not None: # Invalid index provided\n",
        "            # console.print(f\"[yellow]Warning: Invalid solution_to_compare_idx ({solution_to_compare_idx}). Using best performer or Solution 1.[/yellow]\")\n",
        "            # Fallback to best_sol_idx_for_plot determined above, or Solution 1 if control was best\n",
        "            if best_sol_idx_for_plot == -1 and self.num_solution_variants > 0:\n",
        "                 best_sol_idx_for_plot = 0 # Default to Solution 1 for diff plots if control is best\n",
        "                 best_sol_name_for_title = f\"Solution 1\"\n",
        "\n",
        "\n",
        "        if best_sol_idx_for_plot == -1 and self.num_solution_variants > 0 :\n",
        "             best_sol_idx_for_plot = 0 # Default to Solution 1 for diff plots if control is best\n",
        "             best_sol_name_for_title = f\"Solution 1\"\n",
        "        elif self.num_solution_variants == 0: # No solutions to plot differences for\n",
        "            best_sol_name_for_title = \"N/A\"\n",
        "\n",
        "\n",
        "        fig = make_subplots(\n",
        "            rows=3, cols=2,\n",
        "            subplot_titles=(\n",
        "                \"<b>Prior Distributions</b>\",\n",
        "                \"<b>Observed Data Likelihoods</b>\",\n",
        "                \"<b>Posterior Distributions</b>\",\n",
        "                f\"<b>Which Variant is Most Likely the Winner?</b>\",\n",
        "                f\"<b>Absolute Difference: {best_sol_name_for_title} vs. Control</b>\",\n",
        "                f\"<b>Probability of {best_sol_name_for_title} Beating Control by > X% (Relative Lift)</b>\"\n",
        "            ),\n",
        "            specs=[[{}, {}],\n",
        "                   [{}, {}],\n",
        "                   [{}, {}]],\n",
        "            vertical_spacing=0.15,\n",
        "            horizontal_spacing=0.1\n",
        "        )\n",
        "\n",
        "        all_prior_params = [(self.control_prior_alpha, self.control_prior_beta)] + \\\n",
        "                           [(self.solution_prior_alpha[i], self.solution_prior_beta[i]) for i in range(self.num_solution_variants)]\n",
        "        prior_min_x, prior_max_x = self._get_dynamic_axis_range(*all_prior_params, allow_negative=False)\n",
        "        x_prior_plot = np.linspace(prior_min_x, prior_max_x, 200)\n",
        "\n",
        "        all_like_params = [(self.control_observed_alpha_likelihood, self.control_observed_beta_likelihood) if self.control_samples > 0 else None] + \\\n",
        "                          [(self.solution_observed_alpha_likelihood[i], self.solution_observed_beta_likelihood[i]) if self.solution_samples[i] > 0 else None for i in range(self.num_solution_variants)]\n",
        "        like_min_x, like_max_x = self._get_dynamic_axis_range(*[p for p in all_like_params if p is not None], allow_negative=False)\n",
        "        x_like_plot = np.linspace(like_min_x, like_max_x, 200)\n",
        "\n",
        "        all_post_samples = [control_post_s] + [samples_data[f\"solution_{i+1}_rate\"] for i in range(self.num_solution_variants) if f\"solution_{i+1}_rate\" in samples_data]\n",
        "        post_min_x, post_max_x = self._get_dynamic_axis_range(*[s for s in all_post_samples if s is not None and len(s) > 0], allow_negative=False)\n",
        "        x_post_plot = np.linspace(post_min_x, post_max_x, 200)\n",
        "\n",
        "        # Plot 1: Prior Distributions\n",
        "        fig.add_trace(go.Scatter(x=x_prior_plot, y=stats.beta.pdf(x_prior_plot, self.control_prior_alpha, self.control_prior_beta),\n",
        "                                 mode='lines', name='Ctrl Prior', legendgroup=\"Priors\", line=dict(dash='dash', color='skyblue', width=2),\n",
        "                                 hovertemplate=\"<b>Ctrl Prior</b><br>Rate: %{x:.3%}<br>Density: %{y:.2f}<extra></extra>\"), row=1, col=1)\n",
        "        for i in range(self.num_solution_variants):\n",
        "            fig.add_trace(go.Scatter(x=x_prior_plot, y=stats.beta.pdf(x_prior_plot, self.solution_prior_alpha[i], self.solution_prior_beta[i]),\n",
        "                                     mode='lines', name=f'Sol {i+1} Prior', legendgroup=\"Priors\",\n",
        "                                     line=dict(dash='dash', color=solution_line_colors[i % len(solution_line_colors)], width=2),\n",
        "                                     hovertemplate=f\"<b>Sol {i+1} Prior</b><br>Rate: %{{x:.3%}}<br>Density: %{{y:.2f}}<extra></extra>\"), row=1, col=1)\n",
        "        fig.update_xaxes(range=[prior_min_x, prior_max_x], row=1, col=1)\n",
        "\n",
        "        # Plot 2: Observed Data Likelihoods\n",
        "        if self.control_samples > 0:\n",
        "            fig.add_trace(go.Scatter(x=x_like_plot, y=stats.beta.pdf(x_like_plot, self.control_observed_alpha_likelihood, self.control_observed_beta_likelihood),\n",
        "                                     mode='lines', name='Ctrl Likelihood', legendgroup=\"Likelihoods\", line=dict(dash='dot', color='lightgreen', width=2),\n",
        "                                     hovertemplate=\"<b>Ctrl Likelihood</b><br>Rate: %{x:.3%}<br>Density: %{y:.2f}<extra></extra>\"), row=1, col=2)\n",
        "        for i in range(self.num_solution_variants):\n",
        "            if self.solution_samples[i] > 0:\n",
        "                fig.add_trace(go.Scatter(x=x_like_plot, y=stats.beta.pdf(x_like_plot, self.solution_observed_alpha_likelihood[i], self.solution_observed_beta_likelihood[i]),\n",
        "                                         mode='lines', name=f'Sol {i+1} Likelihood', legendgroup=\"Likelihoods\",\n",
        "                                         line=dict(dash='dot', color=solution_line_colors[i % len(solution_line_colors)], width=1.5),\n",
        "                                         opacity=0.8,\n",
        "                                         hovertemplate=f\"<b>Sol {i+1} Likelihood</b><br>Rate: %{{x:.3%}}<br>Density: %{{y:.2f}}<extra></extra>\"), row=1, col=2)\n",
        "        if self.control_samples == 0 and all(s == 0 for s in self.solution_samples):\n",
        "             fig.add_annotation(text=\"No observed data entered\", showarrow=False, row=1, col=2)\n",
        "        fig.update_xaxes(range=[like_min_x, like_max_x], row=1, col=2)\n",
        "\n",
        "        # Plot 3: Posterior Distributions\n",
        "        # max_density_post = 0 # Not used, can be removed\n",
        "        if control_post_s is not None and len(control_post_s) > 1:\n",
        "            kde_control = stats.gaussian_kde(control_post_s)\n",
        "            y_kde_control = kde_control(x_post_plot)\n",
        "            # max_density_post = max(max_density_post, np.max(y_kde_control) if len(y_kde_control)>0 else 0)\n",
        "            fig.add_trace(go.Scatter(x=x_post_plot, y=y_kde_control, mode='lines', name='Ctrl Posterior', legendgroup=\"Posteriors\", fill='tozeroy',\n",
        "                                     fillcolor='rgba(70,130,180,0.4)', line=dict(color='steelblue', width=2),\n",
        "                                     hovertemplate=\"<b>Ctrl Posterior</b><br>Rate: %{x:.3%}<br>Density: %{y:.2f}<extra></extra>\"), row=2, col=1)\n",
        "        for i in range(self.num_solution_variants):\n",
        "            sol_s_key = f\"solution_{i+1}_rate\"\n",
        "            if sol_s_key in samples_data:\n",
        "                sol_s = samples_data[sol_s_key]\n",
        "                if sol_s is not None and len(sol_s) > 1:\n",
        "                    kde_solution = stats.gaussian_kde(sol_s)\n",
        "                    y_kde_solution = kde_solution(x_post_plot)\n",
        "                    # max_density_post = max(max_density_post, np.max(y_kde_solution) if len(y_kde_solution)>0 else 0)\n",
        "                    fig.add_trace(go.Scatter(x=x_post_plot, y=y_kde_solution, mode='lines', name=f'Sol {i+1} Posterior', legendgroup=\"Posteriors\", fill='tozeroy',\n",
        "                                            fillcolor=solution_fill_colors[i % len(solution_fill_colors)],\n",
        "                                            line=dict(color=solution_line_colors[i % len(solution_line_colors)], width=2),\n",
        "                                            hovertemplate=f\"<b>Sol {i+1} Posterior</b><br>Rate: %{{x:.3%}}<br>Density: %{{y:.2f}}<extra></extra>\"), row=2, col=1)\n",
        "        fig.update_xaxes(range=[post_min_x, post_max_x], row=2, col=1)\n",
        "\n",
        "        # Plot 4: Probability of Being Best\n",
        "        prob_best_names = [self.variant_names[0]] + [sol_metrics['name'] for sol_metrics in metrics_temp['solutions']]\n",
        "        prob_best_values = [metrics_temp.get('prob_control_is_best', 0)] + [sol_metrics.get('prob_is_best', 0) for sol_metrics in metrics_temp['solutions']]\n",
        "        bar_colors = ['skyblue'] + [solution_line_colors[i % len(solution_line_colors)] for i in range(self.num_solution_variants)]\n",
        "        fig.add_trace(go.Bar(x=prob_best_names, y=prob_best_values, name='P(Best)', legendgroup=\"P(Best)\",\n",
        "                             marker_color=bar_colors, text=[f\"{p:.1%}\" for p in prob_best_values], textposition='auto',\n",
        "                             hovertemplate=\"<b>%{x}</b><br>P(Best): %{y:.2%}<extra></extra>\"), row=2, col=2)\n",
        "        fig.update_yaxes(tickformat=\".0%\", range=[0,1.05], row=2, col=2)\n",
        "\n",
        "        # Plot 5: Difference (Selected/Best Solution vs Control)\n",
        "        selected_sol_abs_diff_s = np.array([])\n",
        "        if best_sol_idx_for_plot != -1 and f\"abs_diff_s{best_sol_idx_for_plot+1}_c\" in samples_data:\n",
        "            selected_sol_abs_diff_s = samples_data[f\"abs_diff_s{best_sol_idx_for_plot+1}_c\"]\n",
        "\n",
        "        if len(selected_sol_abs_diff_s) > 1:\n",
        "            diff_min_x, diff_max_x = self._get_dynamic_axis_range(selected_sol_abs_diff_s, allow_negative=True)\n",
        "            x_diff_plot = np.linspace(diff_min_x, diff_max_x, 200)\n",
        "            kde_abs_diff = stats.gaussian_kde(selected_sol_abs_diff_s)\n",
        "            y_kde_abs_diff = kde_abs_diff(x_diff_plot)\n",
        "            fig.add_trace(go.Scatter(x=x_diff_plot, y=y_kde_abs_diff, mode='lines', name=f'Abs. Diff ({best_sol_name_for_title})', legendgroup=\"Difference Analysis\", fill='tozeroy',\n",
        "                                     fillcolor='rgba(128,0,128,0.4)', line=dict(color='purple', width=2),\n",
        "                                     hovertemplate=\"<b>Abs. Difference</b><br>Value: %{x:.3%}<br>Density: %{y:.2f}<extra></extra>\"), row=3, col=1)\n",
        "            abs_diff_mean = np.mean(selected_sol_abs_diff_s)\n",
        "            abs_diff_hdi = _calculate_hdi(selected_sol_abs_diff_s)\n",
        "            fig.add_vline(x=abs_diff_mean, line_width=1.5, line_dash=\"dash\", line_color=\"indigo\", row=3, col=1)\n",
        "            fig.add_vline(x=abs_diff_hdi[0], line_width=1.5, line_dash=\"dot\", line_color=\"indigo\", row=3, col=1)\n",
        "            fig.add_vline(x=abs_diff_hdi[1], line_width=1.5, line_dash=\"dot\", line_color=\"indigo\", row=3, col=1)\n",
        "            if rope_abs_diff: # Check if rope_abs_diff is defined\n",
        "                fig.add_shape(type=\"rect\", x0=rope_abs_diff[0], x1=rope_abs_diff[1], y0=0, y1=np.max(y_kde_abs_diff)*1.1 if len(y_kde_abs_diff) > 0 else 1,\n",
        "                            fillcolor=\"rgba(169,169,169,0.3)\", opacity=0.3, layer=\"below\", line_width=0, name=\"ROPE Abs.Diff.\", row=3, col=1)\n",
        "            fig.update_xaxes(range=[diff_min_x, diff_max_x], row=3, col=1)\n",
        "        elif self.num_solution_variants > 0 : # Only add annotation if solutions exist but no data for this plot\n",
        "            fig.add_annotation(text=f\"No data for Absolute Difference plot ({best_sol_name_for_title})\", showarrow=False, row=3, col=1)\n",
        "        else: # No solutions at all\n",
        "            fig.add_annotation(text=\"No solution variants to compare.\", showarrow=False, row=3, col=1)\n",
        "\n",
        "\n",
        "        # Plot 6: Cumulative P(Selected/Best Solution Relative Uplift > X)\n",
        "        selected_sol_rel_lift_s = np.array([])\n",
        "        if best_sol_idx_for_plot != -1 and f\"rel_lift_s{best_sol_idx_for_plot+1}_c\" in samples_data:\n",
        "            selected_sol_rel_lift_s = samples_data[f\"rel_lift_s{best_sol_idx_for_plot+1}_c\"][~np.isnan(samples_data[f\"rel_lift_s{best_sol_idx_for_plot+1}_c\"])]\n",
        "\n",
        "        if len(selected_sol_rel_lift_s) > 0:\n",
        "            cum_rel_min_x, cum_rel_max_x = self._get_dynamic_axis_range(selected_sol_rel_lift_s, allow_negative=True)\n",
        "            sorted_rel_lift = np.sort(selected_sol_rel_lift_s)\n",
        "            y_cumulative_rel = 1. - (np.arange(len(sorted_rel_lift)) / float(len(sorted_rel_lift)))\n",
        "            fig.add_trace(go.Scatter(x=sorted_rel_lift, y=y_cumulative_rel, mode='lines', name=f'P(Rel. Uplift ({best_sol_name_for_title}) > X)', legendgroup=\"Cumulative Uplift\", line=dict(color='darkcyan', width=2),\n",
        "                                     hovertemplate=\"<b>P(Rel. Uplift > X)</b><br>Rel. Uplift (X): %{x:.2%}<br>Probability: %{y:.2%}<extra></extra>\"), row=3, col=2)\n",
        "            fig.add_hline(y=0.95, line_width=1, line_dash=\"dash\", line_color=\"gray\", row=3, col=2)\n",
        "            fig.add_hline(y=0.50, line_width=1, line_dash=\"dot\", line_color=\"gray\", row=3, col=2)\n",
        "            fig.add_vline(x=0, line_width=1, line_dash=\"solid\", line_color=\"black\", row=3, col=2)\n",
        "            fig.update_xaxes(range=[cum_rel_min_x, cum_rel_max_x], row=3, col=2)\n",
        "            fig.update_yaxes(range=[0,1.05], row=3, col=2)\n",
        "        elif self.num_solution_variants > 0:\n",
        "             fig.add_annotation(text=f\"Not enough data for Cumulative Rel. Uplift ({best_sol_name_for_title})\", showarrow=False, row=3, col=2)\n",
        "        else:\n",
        "             fig.add_annotation(text=\"No solution variants to compare.\", showarrow=False, row=3, col=2)\n",
        "\n",
        "\n",
        "        fig.update_layout(\n",
        "            height=1200,\n",
        "            title_text=\"<b>Bayesian A/B Test Visualizations</b>\", title_x=0.5, title_font_size=20,\n",
        "            legend_traceorder='grouped', legend_tracegroupgap=15, hovermode='x unified', template='plotly_white'\n",
        "        )\n",
        "        for r_idx,c_idx in [(1,1),(1,2),(2,1),(2,2),(3,1),(3,2)]: fig.update_xaxes(tickformat=\".2%\", row=r_idx, col=c_idx) # Use r_idx, c_idx to avoid conflict\n",
        "        for r_idx,c_idx in [(1,1),(1,2),(2,1),(3,1)]: fig.update_yaxes(title_text=\"Density\", row=r_idx, col=c_idx) # Use r_idx, c_idx\n",
        "        fig.update_yaxes(title_text=\"Probability P(Best)\", tickformat=\".0%\", row=2, col=2)\n",
        "        fig.update_yaxes(title_text=\"Probability P(Rel. Uplift > X)\", tickformat=\".0%\", row=3, col=2)\n",
        "\n",
        "        fig.show() # This will render directly in Colab output, not in the HTML box\n",
        "\n",
        "    def plot_forest_hdi(self, metrics):\n",
        "        \"\"\"\n",
        "        Generates and displays a forest plot of the 95% HDIs for conversion rates.\n",
        "        Note: Plotly fig.show() renders directly to Colab output, not captured in the tall text box.\n",
        "        \"\"\"\n",
        "        variant_names = [\"Control\"] + [sol['name'] for sol in metrics['solutions']]\n",
        "        mean_rates = [metrics['control']['posterior_mean_rate']] + [sol['posterior_mean_rate'] for sol in metrics['solutions']]\n",
        "        hdi_lows = [metrics['control']['rate_hdi'][0]] + [sol['rate_hdi'][0] for sol in metrics['solutions']]\n",
        "        hdi_highs = [metrics['control']['rate_hdi'][1]] + [sol['rate_hdi'][1] for sol in metrics['solutions']]\n",
        "\n",
        "        control_color = 'rgba(70,130,180,0.8)'\n",
        "        solution_base_colors = ['rgba(240,128,128,0.8)', 'rgba(32,178,170,0.8)', 'rgba(147,112,219,0.8)', 'rgba(255,215,0,0.8)']\n",
        "        variant_colors = [control_color] + [solution_base_colors[i % len(solution_base_colors)] for i in range(self.num_solution_variants)]\n",
        "\n",
        "        fig = go.Figure()\n",
        "\n",
        "        for i in range(len(variant_names)):\n",
        "            # Skip if HDI is nan, which can happen with no samples\n",
        "            if np.isnan(hdi_lows[i]) or np.isnan(hdi_highs[i]):\n",
        "                continue\n",
        "            fig.add_trace(go.Scatter(\n",
        "                x=[hdi_lows[i], hdi_highs[i]],\n",
        "                y=[variant_names[i], variant_names[i]],\n",
        "                mode='lines',\n",
        "                line=dict(color=variant_colors[i], width=2),\n",
        "                name=f\"{variant_names[i]} 95% HDI\",\n",
        "                legendgroup=variant_names[i],\n",
        "                showlegend=False,\n",
        "                hovertemplate=f\"<b>{variant_names[i]}</b><br>95% HDI: [{hdi_lows[i]:.2%}, {hdi_highs[i]:.2%}]<extra></extra>\"\n",
        "            ))\n",
        "            if not np.isnan(mean_rates[i]): # Also check mean_rate for NaN\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=[mean_rates[i]],\n",
        "                    y=[variant_names[i]],\n",
        "                    mode='markers',\n",
        "                    marker=dict(color=variant_colors[i], size=10, symbol='diamond'),\n",
        "                    name=variant_names[i],\n",
        "                    legendgroup=variant_names[i],\n",
        "                    hovertemplate=f\"<b>{variant_names[i]}</b><br>Mean Rate: {mean_rates[i]:.2%}<br>95% HDI: [{hdi_lows[i]:.2%}, {hdi_highs[i]:.2%}]<extra></extra>\"\n",
        "                ))\n",
        "\n",
        "        if not np.isnan(metrics['control']['posterior_mean_rate']):\n",
        "            fig.add_vline(\n",
        "                x=metrics['control']['posterior_mean_rate'],\n",
        "                line_width=1, line_dash=\"dash\", line_color=\"grey\",\n",
        "                annotation_text=\"Control Mean\", annotation_position=\"bottom right\"\n",
        "            )\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=\"<b>Credible Conversion Rates (95% HDI)</b>\",\n",
        "            title_x=0.5,\n",
        "            xaxis_title=\"Conversion Rate\",\n",
        "            yaxis_title=\"Variant\",\n",
        "            yaxis=dict(autorange=\"reversed\"),\n",
        "            template='plotly_white',\n",
        "            height=150 + (len(variant_names) * 50),\n",
        "            hovermode='closest',\n",
        "            legend_title_text='Variants'\n",
        "        )\n",
        "        fig.update_xaxes(tickformat=\".2%\")\n",
        "        fig.show() # This will render directly in Colab output, not in the HTML box\n",
        "\n",
        "\n",
        "# --- Display Helper Functions --- (These use `console.print` which will be captured)\n",
        "def display_test_outcomes_table(console, metrics):\n",
        "    \"\"\"Displays the Test Outcomes table for multiple variants.\"\"\"\n",
        "    table = Table(title=\"Test Outcomes Summary\", title_style=\"bold magenta\", border_style=\"blue\")\n",
        "    table.add_column(\"Group\", style=\"cyan\")\n",
        "    table.add_column(\"Win Rate (Mean)\", style=\"dim\")\n",
        "    table.add_column(\"Rel. Lift vs Ctrl (Mean)\", style=\"dim\")\n",
        "    table.add_column(\"95% HDI (Rate)\", style=\"dim\")\n",
        "\n",
        "    c_metrics = metrics['control']\n",
        "    c_rate_hdi_low, c_rate_hdi_high = c_metrics.get('rate_hdi', (np.nan, np.nan))\n",
        "    table.add_row(\"Control\",\n",
        "                  f\"{c_metrics.get('posterior_mean_rate', np.nan):.2%}\",\n",
        "                  \"N/A\",\n",
        "                  f\"[{c_rate_hdi_low:.2%}, {c_rate_hdi_high:.2%}]\")\n",
        "\n",
        "    for sol_metrics in metrics['solutions']:\n",
        "        rl_mean = sol_metrics.get('relative_lift_mean', np.nan)\n",
        "        rate_hdi_low, rate_hdi_high = sol_metrics.get('rate_hdi', (np.nan, np.nan))\n",
        "        table.add_row(\n",
        "            sol_metrics.get('name', 'N/A'),\n",
        "            f\"{sol_metrics.get('posterior_mean_rate', np.nan):.2%}\",\n",
        "            f\"{rl_mean:+.2%}\" if not np.isnan(rl_mean) else \"N/A\",\n",
        "            f\"[{rate_hdi_low:.2%}, {rate_hdi_high:.2%}]\"\n",
        "        )\n",
        "    console.print(Padding(table, (1, 0)))\n",
        "\n",
        "\n",
        "def display_confidence_intervals_summary(console, metrics):\n",
        "    \"\"\"Displays a dedicated summary of key confidence intervals for multiple variants.\"\"\"\n",
        "    panel_content = Text()\n",
        "    c_metrics = metrics['control']\n",
        "    c_rate_hdi_low, c_rate_hdi_high = c_metrics.get('rate_hdi', (np.nan, np.nan))\n",
        "    panel_content.append(\"Control Conversion Rate:\\n\", style=\"bold sky_blue3\")\n",
        "    panel_content.append(f\"  Mean: {c_metrics.get('posterior_mean_rate', np.nan):.2%}, 95% HDI: [{c_rate_hdi_low:.2%}, {c_rate_hdi_high:.2%}]\\n\\n\")\n",
        "\n",
        "    for sol_metrics in metrics['solutions']:\n",
        "        sol_name = sol_metrics.get('name', 'N/A')\n",
        "        sol_rate_hdi_low, sol_rate_hdi_high = sol_metrics.get('rate_hdi', (np.nan, np.nan))\n",
        "        panel_content.append(f\"{sol_name} Conversion Rate:\\n\", style=\"bold light_coral\")\n",
        "        panel_content.append(f\"  Mean: {sol_metrics.get('posterior_mean_rate', np.nan):.2%}, 95% HDI: [{sol_rate_hdi_low:.2%}, {sol_rate_hdi_high:.2%}]\\n\\n\")\n",
        "\n",
        "        abs_diff_hdi_low, abs_diff_hdi_high = sol_metrics.get('absolute_difference_hdi', (np.nan, np.nan))\n",
        "        panel_content.append(f\"Abs. Diff ({sol_name} - Control):\\n\", style=\"bold dark_violet\")\n",
        "        panel_content.append(f\"  Mean: {sol_metrics.get('absolute_difference_mean', np.nan):.2%}, 95% HDI: [{abs_diff_hdi_low:.2%}, {abs_diff_hdi_high:.2%}]\\n\")\n",
        "\n",
        "        rl_mean_val = sol_metrics.get('relative_lift_mean', np.nan)\n",
        "        rl_hdi_low_val, rl_hdi_high_val = sol_metrics.get('relative_lift_hdi', (np.nan, np.nan))\n",
        "        if not np.isnan(rl_mean_val):\n",
        "            panel_content.append(f\"Rel. Lift (({sol_name}-Ctrl)/Ctrl):\\n\", style=\"bold green4\")\n",
        "            panel_content.append(f\"  Mean: {rl_mean_val:.2%}, 95% HDI: [{rl_hdi_low_val:.2%}, {rl_hdi_high_val:.2%}]\\n\\n\")\n",
        "        else:\n",
        "            panel_content.append(f\"Rel. Lift (({sol_name}-Ctrl)/Ctrl): N/A (Control rate might be zero or too low)\\n\\n\")\n",
        "\n",
        "    console.print(Panel(panel_content, title=\"[bold]Confidence Intervals (95% HDI)[/bold]\", border_style=\"steel_blue\", expand=False))\n",
        "\n",
        "\n",
        "def display_detailed_metrics(console, metrics, rope_abs_diff, rope_rel_lift):\n",
        "    panel_content = Text()\n",
        "    prob_beat_thresh_val_display = metrics.get('prob_beat_threshold_value', 0.0)\n",
        "\n",
        "    panel_content.append(\"Probability of Being Best Overall:\\n\", style=\"bold underline\")\n",
        "    panel_content.append(f\"  Control: {metrics.get('prob_control_is_best', 0.0):.2%}\\n\")\n",
        "    for sol_metrics in metrics['solutions']:\n",
        "        panel_content.append(f\"  {sol_metrics.get('name','N/A')}: {sol_metrics.get('prob_is_best', 0.0):.2%}\\n\")\n",
        "    panel_content.append(\"\\n\")\n",
        "\n",
        "    for i, sol_metrics in enumerate(metrics['solutions']):\n",
        "        sol_name = sol_metrics.get('name','N/A')\n",
        "        panel_content.append(f\"--- Analysis for {sol_name} vs Control ---\\n\", style=\"bold yellow\")\n",
        "        panel_content.append(\"Probabilities:\\n\", style=\"bold underline\")\n",
        "        panel_content.append(f\"  P({sol_name} > Control): {sol_metrics.get('prob_beats_control',np.nan):.2%}\\n\")\n",
        "        panel_content.append(f\"  P({sol_name} > Control + {prob_beat_thresh_val_display:.1%}): {sol_metrics.get('prob_beats_control_by_threshold',np.nan):.2%}\\n\\n\")\n",
        "\n",
        "        if rope_abs_diff: # Check if ROPE for absolute difference is defined\n",
        "            panel_content.append(f\"ROPE Analysis (Absolute Difference: {rope_abs_diff[0]:.2%} to {rope_abs_diff[1]:.2%}):\\n\", style=\"bold underline\")\n",
        "            panel_content.append(f\"  P(Diff < ROPE Low): {sol_metrics.get('prob_abs_diff_below_rope',np.nan):.2%}\\n\")\n",
        "            panel_content.append(f\"  P(Diff In ROPE):   {sol_metrics.get('prob_abs_diff_in_rope',np.nan):.2%}\\n\")\n",
        "            panel_content.append(f\"  P(Diff > ROPE High):{sol_metrics.get('prob_abs_diff_above_rope',np.nan):.2%}\\n\\n\")\n",
        "        else:\n",
        "            panel_content.append(\"ROPE Analysis (Absolute Difference): Not applicable (e.g. control rate is zero).\\n\\n\")\n",
        "\n",
        "\n",
        "        if not np.isnan(sol_metrics.get('prob_rel_lift_in_rope', np.nan)) and rope_rel_lift:\n",
        "            panel_content.append(f\"ROPE Analysis (Relative Lift: {rope_rel_lift[0]:.1%} to {rope_rel_lift[1]:.1%}):\\n\", style=\"bold underline\")\n",
        "            panel_content.append(f\"  P(Lift < ROPE Low): {sol_metrics.get('prob_rel_lift_below_rope', np.nan):.2%}\\n\")\n",
        "            panel_content.append(f\"  P(Lift In ROPE):   {sol_metrics.get('prob_rel_lift_in_rope', np.nan):.2%}\\n\")\n",
        "            panel_content.append(f\"  P(Lift > ROPE High):{sol_metrics.get('prob_rel_lift_above_rope', np.nan):.2%}\\n\\n\")\n",
        "        else:\n",
        "            panel_content.append(\"ROPE Analysis (Relative Lift): Not applicable (e.g. control rate is zero or ROPE not defined).\\n\\n\")\n",
        "\n",
        "\n",
        "        panel_content.append(f\"Expected Loss ({sol_name} vs Control):\\n\", style=\"bold underline\")\n",
        "        panel_content.append(f\"  Choosing {sol_name} (if Control is better): {sol_metrics.get('expected_loss_vs_control_choosing_solution',np.nan):.4%}\\n\")\n",
        "        panel_content.append(f\"  Choosing Control (if {sol_name} is better): {sol_metrics.get('expected_loss_vs_control_choosing_control',np.nan):.4%}\\n\\n\")\n",
        "\n",
        "    console.print(Panel(panel_content, title=\"[bold]Further Analysis Details[/bold]\", border_style=\"green\", expand=False))\n",
        "\n",
        "def display_explanations(console):\n",
        "    text = Text()\n",
        "    text.append(\"Key Concepts:\\n\\n\", style=\"bold underline\")\n",
        "    text.append(\"ROPE (Region of Practical Equivalence):\\n\", style=\"bold cyan\")\n",
        "    text.append(\"  The range of differences you consider too small to matter. If the credible interval for the difference falls mostly within ROPE, the variants are practically equivalent.\\n\\n\")\n",
        "    text.append(\"HDI (Highest Density Interval):\\n\", style=\"bold cyan\")\n",
        "    text.append(\"  The range containing a specific percentage (e.g., 95%) of the most credible values for a parameter (e.g., conversion rate or difference). We can say there's a 95% probability the true value lies within the 95% HDI.\\n\\n\")\n",
        "    text.append(\"Interpreting 'Further Analysis Details':\\n\", style=\"bold underline\")\n",
        "    text.append(\"  - Probability of Being Best: For each variant, the chance it has the highest true conversion rate among all tested variants (including Control).\\n\")\n",
        "    text.append(\"  - Probabilities (vs Control): Shows the likelihood of a solution variant being better than Control, or better by a certain threshold.\\n\")\n",
        "    text.append(\"  - ROPE Analysis (vs Control): Shows the probability that the true difference/lift between a solution and Control falls below, within, or above your defined ROPE.\\n\")\n",
        "    text.append(\"  - Expected Loss (vs Control): Estimates the average 'cost' of making the wrong decision between a specific solution and Control.\\n\\n\")\n",
        "    text.append(\"Interpreting Charts:\\n\", style=\"bold underline\")\n",
        "    text.append(\"  - Prior plots show initial beliefs for Control and all Solutions, overlaid.\\n\")\n",
        "    text.append(\"  - Likelihood plots show what current test data suggests for each variant, overlaid.\\n\")\n",
        "    text.append(\"  - Posterior plots combine priors and likelihood for updated beliefs, overlaid. HDIs are marked as small shaded regions at the base.\\n\")\n",
        "    text.append(\"  - P(Best) Bar Chart: Visualizes the probability of each variant being the overall best.\\n\")\n",
        "    text.append(\"  - Difference plots show distributions of (Solution - Control) for the best solution or a selected one.\\n\")\n",
        "    text.append(\"  - Cumulative P(Uplift > X) plot shows the probability that the true relative uplift (for the best solution vs Control) is greater than X.\\n\")\n",
        "    text.append(\"  - Forest Plot: Compares the 95% HDIs of conversion rates for all variants side-by-side.\\n\")\n",
        "    text.append(\"  - Hover over chart elements for specific values.\\n\")\n",
        "    console.print(Panel(text, title=\"[bold]Understanding the Results[/bold]\", border_style=\"magenta\", expand=False))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Colab Form Inputs ---\n",
        "    # @title Bayesian A/B Test Analyzer Inputs\n",
        "    # @markdown ### General Setup\n",
        "    Number_of_Solution_Variants = 1 #@param {type:\"integer\", min:1, max:5, step:1}\n",
        "\n",
        "    # @markdown ---\n",
        "    # @markdown ### Prior Input Method\n",
        "    # @markdown Choose how to define your prior beliefs. \"Assumed Rate & Strength\" is generally more intuitive.\n",
        "    Prior_Input_Method = \"Assumed Rate & Strength (Recommended)\" #@param [\"Assumed Rate & Strength (Recommended)\", \"Direct Alpha & Beta (Advanced)\"]\n",
        "\n",
        "    # @markdown ---\n",
        "    # @markdown ### Priors: Control Group\n",
        "    # @markdown Based on your chosen input method:\n",
        "    Control_Assumed_Conversion_Rate = 0.10 #@param {type:\"number\"}\n",
        "    Control_Prior_Strength_Pseudo_Observations = 100 #@param {type:\"integer\"}\n",
        "    # @markdown ---\n",
        "    # @markdown *Advanced: Direct Alpha/Beta for Control (only used if \"Direct Alpha & Beta\" method is selected above)*\n",
        "    Control_Prior_Alpha_Advanced = 1.0 #@param {type:\"number\"}\n",
        "    Control_Prior_Beta_Advanced = 1.0 #@param {type:\"number\"}\n",
        "\n",
        "    # @markdown ---\n",
        "    # @markdown ### Priors: Solution Variant(s)\n",
        "    Auto_Derive_Solution_Priors_From_Control_Rate = True #@param {type:\"boolean\"}\n",
        "    # @markdown *If auto-deriving: Uses Control's Assumed Rate. Enter Strength (CSV for multiple, e.g., \"20\" or \"20,15\").*\n",
        "    Solution_Priors_Strength_CSV_Auto = \"100\" #@param {type:\"string\"}\n",
        "    # @markdown *If NOT auto-deriving (and using Rate & Strength method): Enter Assumed Rates (CSV, e.g., \"0.12,0.15\") and Strengths (CSV, e.g., \"20,25\") for each solution.*\n",
        "    Solution_Assumed_Rates_CSV_Manual = \"0.12\" #@param {type:\"string\"}\n",
        "    Solution_Priors_Strength_CSV_Manual = \"20\" #@param {type:\"string\"}\n",
        "    # @markdown ---\n",
        "    # @markdown *Advanced: Direct Alpha/Beta for Solutions (CSV, e.g., \"1,1\"). Only used if \"Direct Alpha & Beta\" method is selected.*\n",
        "    Solution_Prior_Alphas_Advanced_CSV = \"1.0\" #@param {type:\"string\"}\n",
        "    Solution_Prior_Betas_Advanced_CSV = \"1.0\" #@param {type:\"string\"}\n",
        "\n",
        "    # @markdown ---\n",
        "    # @markdown ### Test Results\n",
        "    # @markdown **Control Group:**\n",
        "    Control_Group_Samples = 6000 #@param {type:\"integer\"}\n",
        "    Control_Group_Conversions = 600 #@param {type:\"integer\"}\n",
        "    # @markdown **Solution Group(s):**\n",
        "    # @markdown *Enter comma-separated values if multiple solutions (e.g., `1000,1010` for samples).*\n",
        "    Solution_Samples_CSV = \"6000\" #@param {type:\"string\"}\n",
        "    Solution_Conversions_CSV = \"610\" #@param {type:\"string\"}\n",
        "\n",
        "    # @markdown ---\n",
        "    # @markdown ### ROPE (Region of Practical Equivalence)\n",
        "    ROPE_Definition_Method = \"Relative Lift (%)\" #@param [\"Relative Lift (%)\", \"Absolute Difference (Decimal)\"]\n",
        "    # @markdown *Enter a positive value for the symmetrical boundary. E.g., for +/-2%, enter 2.*\n",
        "    ROPE_Relative_Lift_Symmetrical_Boundary_Percent = 1.0 #@param {type:\"number\"}\n",
        "    # @markdown *Enter a positive decimal for the symmetrical boundary. E.g., for +/-0.5%, enter 0.005.*\n",
        "    ROPE_Absolute_Difference_Symmetrical_Boundary_Decimal = 0.005 #@param {type:\"number\"}\n",
        "\n",
        "    # @markdown ---\n",
        "    # @markdown ### Decision Making Parameters\n",
        "    # @markdown *Probability threshold for P(Solution > Control + Uplift Threshold) to be considered 'high enough' for stronger recommendations.*\n",
        "    P_Beats_Control_Threshold_for_Decision = 0.95 #@param {type:\"number\", min:0.5, max:0.999, step:0.01}\n",
        "    # @markdown *Minimum Uplift Threshold (decimal, e.g., 0.001 for 0.1%) for calculating P(Solution > Control + Threshold). This is the 'X' in P(Sol > Ctrl + X).*\n",
        "    Min_Uplift_Threshold_Decimal_for_Prob_Calc = 0.000 #@param {type:\"number\"}\n",
        "    # @markdown *Loss Ratio Threshold: How many times greater must Expected Loss of Choosing Control (if Solution is better) be, compared to Expected Loss of Choosing Solution (if Control is better), to consider the risk profile 'favorable' for the Solution? (e.g., 5 means 5x)*\n",
        "    Loss_Ratio_Threshold_for_Favorable_Risk = 5.0 #@param {type:\"number\", min:1.0}\n",
        "\n",
        "\n",
        "    # @markdown ---\n",
        "    # @markdown ### Plot Settings\n",
        "    # @markdown *Select which Solution variant's difference plots to display. Default is the one with highest P(Best).*\n",
        "    # Dynamically create dropdown options for solution comparison plot\n",
        "    solution_plot_options_list = [\"Best Performer (Default)\"] + [f\"Solution {i+1}\" for i in range(Number_of_Solution_Variants)]\n",
        "    Variant_to_Display_in_Difference_Plots = \"Best Performer (Default)\" #@param [\"Best Performer (Default)\"] {allow-input: true}\n",
        "\n",
        "    # Initialize console here, after stdout redirection and before any prints.\n",
        "    # The Console instance will pick up the redirected sys.stdout.\n",
        "    console = Console()\n",
        "\n",
        "    try:\n",
        "        # --- Process Form Inputs ---\n",
        "        num_solution_variants = int(Number_of_Solution_Variants)\n",
        "\n",
        "        solution_prior_alphas = []\n",
        "        solution_prior_betas = []\n",
        "\n",
        "        if Prior_Input_Method == \"Assumed Rate & Strength (Recommended)\":\n",
        "            control_prior_rate = float(Control_Assumed_Conversion_Rate)\n",
        "            control_prior_strength = int(Control_Prior_Strength_Pseudo_Observations)\n",
        "            if not (0 <= control_prior_rate <= 1): raise ValueError(\"Control Assumed Conversion Rate must be between 0 and 1.\")\n",
        "            if control_prior_strength < 2: raise ValueError(\"Control Prior Strength must be at least 2.\")\n",
        "            control_prior_alpha = control_prior_rate * control_prior_strength\n",
        "            control_prior_beta = (1 - control_prior_rate) * control_prior_strength\n",
        "            # Ensure alpha and beta are at least 1 for a proper Beta distribution\n",
        "            if control_prior_alpha < 1.0: control_prior_alpha = 1.0; control_prior_beta = float(max(1.0, control_prior_strength - 1.0))\n",
        "            if control_prior_beta < 1.0: control_prior_beta = 1.0; control_prior_alpha = float(max(1.0, control_prior_strength - 1.0))\n",
        "\n",
        "            if Auto_Derive_Solution_Priors_From_Control_Rate:\n",
        "                try:\n",
        "                    strengths_csv = Solution_Priors_Strength_CSV_Auto.split(',')\n",
        "                    if len(strengths_csv) == 1 and num_solution_variants > 1: strengths_csv = [strengths_csv[0]] * num_solution_variants # Apply single value to all\n",
        "                    if len(strengths_csv) != num_solution_variants: raise ValueError(f\"Solution Priors Strength CSV count ({len(strengths_csv)}) must match Number of Solution Variants ({num_solution_variants}).\")\n",
        "                    solution_prior_strengths = [int(s.strip()) for s in strengths_csv]\n",
        "                except Exception as e: raise ValueError(f\"Invalid Solution_Priors_Strength_CSV_Auto format: {e}\")\n",
        "\n",
        "                for strength in solution_prior_strengths:\n",
        "                    if strength < 2: raise ValueError(\"Solution Prior Strength must be at least 2.\")\n",
        "                    s_alpha = control_prior_rate * strength # Use control_prior_rate for auto-derivation\n",
        "                    s_beta = (1-control_prior_rate) * strength\n",
        "                    if s_alpha < 1.0: s_alpha = 1.0; s_beta = float(max(1.0, strength - 1.0))\n",
        "                    if s_beta < 1.0: s_beta = 1.0; s_alpha = float(max(1.0, strength - 1.0))\n",
        "                    solution_prior_alphas.append(s_alpha)\n",
        "                    solution_prior_betas.append(s_beta)\n",
        "            else: # Manual rate & strength for solutions\n",
        "                try:\n",
        "                    rates_csv = Solution_Assumed_Rates_CSV_Manual.split(',')\n",
        "                    strengths_csv = Solution_Priors_Strength_CSV_Manual.split(',')\n",
        "                    if len(rates_csv) == 1 and num_solution_variants > 1: rates_csv = [rates_csv[0]] * num_solution_variants\n",
        "                    if len(strengths_csv) == 1 and num_solution_variants > 1: strengths_csv = [strengths_csv[0]] * num_solution_variants\n",
        "                    if len(rates_csv) != num_solution_variants or len(strengths_csv) != num_solution_variants:\n",
        "                        raise ValueError(f\"Manual Solution Assumed Rates/Strengths CSV counts must match Number of Solution Variants ({num_solution_variants}).\")\n",
        "                    solution_assumed_rates = [float(r.strip()) for r in rates_csv]\n",
        "                    solution_prior_strengths = [int(s.strip()) for s in strengths_csv]\n",
        "                except Exception as e: raise ValueError(f\"Invalid format for manual Solution Assumed Rates/Strengths CSV: {e}\")\n",
        "\n",
        "                for i in range(num_solution_variants):\n",
        "                    rate = solution_assumed_rates[i]\n",
        "                    strength = solution_prior_strengths[i]\n",
        "                    if not (0 <= rate <= 1): raise ValueError(f\"Solution {i+1} Assumed Rate must be 0-1.\")\n",
        "                    if strength < 2: raise ValueError(f\"Solution {i+1} Prior Strength must be >= 2.\")\n",
        "                    s_alpha = rate * strength\n",
        "                    s_beta = (1-rate) * strength\n",
        "                    if s_alpha < 1.0: s_alpha = 1.0; s_beta = float(max(1.0, strength - 1.0))\n",
        "                    if s_beta < 1.0: s_beta = 1.0; s_alpha = float(max(1.0, strength - 1.0))\n",
        "                    solution_prior_alphas.append(s_alpha)\n",
        "                    solution_prior_betas.append(s_beta)\n",
        "        else: # Direct Alpha/Beta input\n",
        "            control_prior_alpha = float(Control_Prior_Alpha_Advanced)\n",
        "            control_prior_beta = float(Control_Prior_Beta_Advanced)\n",
        "            if control_prior_alpha <=0 or control_prior_beta <=0: raise ValueError(\"Advanced Control Priors (Alpha, Beta) must be > 0.\")\n",
        "            try:\n",
        "                alphas_csv = Solution_Prior_Alphas_Advanced_CSV.split(',')\n",
        "                betas_csv = Solution_Prior_Betas_Advanced_CSV.split(',')\n",
        "                if len(alphas_csv) == 1 and num_solution_variants > 1: alphas_csv = [alphas_csv[0]] * num_solution_variants\n",
        "                if len(betas_csv) == 1 and num_solution_variants > 1: betas_csv = [betas_csv[0]] * num_solution_variants\n",
        "\n",
        "                solution_prior_alphas = [float(x.strip()) for x in alphas_csv]\n",
        "                solution_prior_betas = [float(x.strip()) for x in betas_csv]\n",
        "\n",
        "                if len(solution_prior_alphas) != num_solution_variants or len(solution_prior_betas) != num_solution_variants:\n",
        "                    raise ValueError(f\"Advanced Solution Alpha/Beta CSV counts must match Number of Solution Variants ({num_solution_variants}).\")\n",
        "                for sa, sb in zip(solution_prior_alphas, solution_prior_betas):\n",
        "                    if sa <=0 or sb <=0: raise ValueError(\"Advanced Solution Priors (Alpha, Beta) must be > 0.\")\n",
        "            except Exception as e: raise ValueError(f\"Invalid format for Advanced Solution Alpha/Beta CSV: {e}\")\n",
        "\n",
        "        # Test Results\n",
        "        control_samples = int(Control_Group_Samples)\n",
        "        control_conversions = int(Control_Group_Conversions)\n",
        "        if control_samples < 0 or control_conversions < 0 or control_conversions > control_samples:\n",
        "            raise ValueError(\"Invalid Control Group samples/conversions.\")\n",
        "        try:\n",
        "            samples_csv = Solution_Samples_CSV.split(',')\n",
        "            conversions_csv = Solution_Conversions_CSV.split(',')\n",
        "            if len(samples_csv) == 1 and num_solution_variants > 1: samples_csv = [samples_csv[0]] * num_solution_variants\n",
        "            if len(conversions_csv) == 1 and num_solution_variants > 1: conversions_csv = [conversions_csv[0]] * num_solution_variants\n",
        "\n",
        "            solution_samples_list = [int(s.strip()) for s in samples_csv]\n",
        "            solution_conversions_list = [int(c.strip()) for c in conversions_csv]\n",
        "\n",
        "            if len(solution_samples_list) != num_solution_variants or len(solution_conversions_list) != num_solution_variants:\n",
        "                raise ValueError(f\"Number of solution samples/conversions entries ({len(solution_samples_list)}/{len(solution_conversions_list)}) must match Number of Solution Variants ({num_solution_variants}).\")\n",
        "            for i in range(num_solution_variants):\n",
        "                if solution_samples_list[i] < 0 or solution_conversions_list[i] < 0 or solution_conversions_list[i] > solution_samples_list[i]:\n",
        "                     raise ValueError(f\"Invalid samples/conversions for Solution {i+1}.\")\n",
        "        except ValueError as e: # Catch specific conversion errors from int() or logic checks\n",
        "            raise ValueError(f\"Invalid format or values for solution samples/conversions. Use comma-separated integers and ensure conversions <= samples. Error: {e}\")\n",
        "        except Exception as e: # Catch other unexpected errors during parsing\n",
        "            raise ValueError(f\"Unexpected error parsing solution samples/conversions: {e}\")\n",
        "\n",
        "\n",
        "        # ROPE\n",
        "        rope_abs_diff = None\n",
        "        rope_rel_lift = None\n",
        "        # Calculate observed control rate, ensure it's float division\n",
        "        control_observed_rate = (float(control_conversions) / control_samples) if control_samples > 0 else 0.0\n",
        "\n",
        "        if ROPE_Definition_Method == \"Relative Lift (%)\":\n",
        "            rel_bound = float(ROPE_Relative_Lift_Symmetrical_Boundary_Percent) / 100.0\n",
        "            if rel_bound < 0: raise ValueError(\"ROPE Relative Lift Symmetrical Boundary Percent must be non-negative.\")\n",
        "            rope_rel_lift = (-rel_bound, rel_bound)\n",
        "            if control_observed_rate > 1e-9: # Avoid division by zero or near-zero\n",
        "                abs_delta = rel_bound * control_observed_rate\n",
        "                rope_abs_diff = (-abs_delta, abs_delta)\n",
        "            else:\n",
        "                console.print(\"[yellow]Warning: Control rate is effectively 0. Cannot derive Absolute ROPE from Relative Lift. Absolute ROPE comparisons will be skipped.[/yellow]\")\n",
        "                # rope_abs_diff remains None\n",
        "        else: # Absolute Difference (Decimal)\n",
        "            abs_bound = float(ROPE_Absolute_Difference_Symmetrical_Boundary_Decimal)\n",
        "            if abs_bound < 0: raise ValueError(\"ROPE Absolute Difference Symmetrical Boundary Decimal must be non-negative.\")\n",
        "            rope_abs_diff = (-abs_bound, abs_bound)\n",
        "            if control_observed_rate > 1e-9:\n",
        "                rel_delta = abs_bound / control_observed_rate\n",
        "                rope_rel_lift = (-rel_delta, rel_delta)\n",
        "            else:\n",
        "                console.print(\"[yellow]Warning: Control rate is effectively 0. Cannot derive Relative ROPE from Absolute Difference. Relative ROPE comparisons will be skipped.[/yellow]\")\n",
        "                # rope_rel_lift remains None\n",
        "\n",
        "        # Decision making parameters from form\n",
        "        p_beats_control_decision_thresh = float(P_Beats_Control_Threshold_for_Decision)\n",
        "        min_uplift_for_prob_calc = float(Min_Uplift_Threshold_Decimal_for_Prob_Calc)\n",
        "        loss_ratio_decision_thresh = float(Loss_Ratio_Threshold_for_Favorable_Risk)\n",
        "        if loss_ratio_decision_thresh < 1.0: raise ValueError(\"Loss Ratio Threshold must be >= 1.0.\")\n",
        "\n",
        "\n",
        "        solution_to_compare_idx_for_plot = None\n",
        "        if Variant_to_Display_in_Difference_Plots != \"Best Performer (Default)\":\n",
        "            try:\n",
        "                selected_solution_name = Variant_to_Display_in_Difference_Plots.strip()\n",
        "                # solution_plot_options_list is defined above the form, ensure it's up-to-date if variants change\n",
        "                current_plot_options = [\"Best Performer (Default)\"] + [f\"Solution {i+1}\" for i in range(num_solution_variants)]\n",
        "                if selected_solution_name in current_plot_options:\n",
        "                    raw_index = current_plot_options.index(selected_solution_name)\n",
        "                    if raw_index > 0:\n",
        "                        solution_to_compare_idx_for_plot = raw_index - 1\n",
        "                    # else: Best Performer, so solution_to_compare_idx_for_plot remains None (handled in plot func)\n",
        "                else:\n",
        "                    console.print(f\"[yellow]Warning: Value '{selected_solution_name}' for 'Variant to Display in Difference Plots' is not a recognized option. Defaulting to best performer.[/yellow]\")\n",
        "            except ValueError:\n",
        "                 console.print(f\"[yellow]Warning: Value '{Variant_to_Display_in_Difference_Plots}' for 'Variant to Display in Difference Plots' is not in the generated options. Defaulting to best performer.[/yellow]\")\n",
        "            except Exception as e:\n",
        "                console.print(f\"[yellow]Could not parse '{Variant_to_Display_in_Difference_Plots}' for comparison plot. Defaulting to best performer. Error: {e}[/yellow]\")\n",
        "\n",
        "        experiment = BayesianExperiment(num_solution_variants=num_solution_variants)\n",
        "        experiment.set_priors(\n",
        "            control_prior_alpha, control_prior_beta,\n",
        "            solution_prior_alphas, solution_prior_betas\n",
        "        )\n",
        "        experiment.update_results(\n",
        "            control_samples, control_conversions,\n",
        "            solution_samples_list, solution_conversions_list\n",
        "        )\n",
        "\n",
        "        console.print(\"\\n[bold]Calculating metrics...[/bold]\\n\")\n",
        "        metrics = experiment.calculate_metrics(\n",
        "            rope_abs_diff=rope_abs_diff if rope_abs_diff is not None else (-0.001, 0.001), # Provide a default if None\n",
        "            rope_rel_lift=rope_rel_lift if rope_rel_lift is not None else (-0.01, 0.01), # Provide a default if None\n",
        "            prob_beat_threshold=min_uplift_for_prob_calc # This is the X in P(Sol > Ctrl + X)\n",
        "        )\n",
        "        # Store the actual uplift threshold value used for display in recommendations\n",
        "        metrics['prob_beat_threshold_value'] = min_uplift_for_prob_calc\n",
        "\n",
        "        evaluation, recommendation, rec_style = experiment.get_decision_summary(\n",
        "            metrics,\n",
        "            rope_abs_diff_vs_control=rope_abs_diff, # Pass the potentially None ROPE\n",
        "            p_threshold=p_beats_control_decision_thresh, # This is the 0.95 like threshold\n",
        "            loss_ratio_threshold=loss_ratio_decision_thresh\n",
        "        )\n",
        "        summary_panel_text = Text()\n",
        "        summary_panel_text.append(\"Evaluation: \", style=\"bold\")\n",
        "        summary_panel_text.append(f\"{evaluation}\\n\", style=f\"bold {rec_style}\")\n",
        "        summary_panel_text.append(\"Recommendation: \", style=\"bold\")\n",
        "        summary_panel_text.append(f\"{recommendation}\", style=f\"bold {rec_style}\")\n",
        "        console.print(Panel(summary_panel_text, title=\"[bold blue]Decision Summary[/bold blue]\", expand=False, border_style=rec_style))\n",
        "\n",
        "        display_test_outcomes_table(console, metrics)\n",
        "        display_confidence_intervals_summary(console, metrics)\n",
        "        display_detailed_metrics(console, metrics, rope_abs_diff, rope_rel_lift)\n",
        "\n",
        "        console.print(Panel(Text(\"Visualizations (Plotly charts will render below this text box)\", justify=\"center\"), title=\"[bold]Charts[/bold]\", border_style=\"yellow\", expand=False))\n",
        "        experiment.plot_distributions_plotly(\n",
        "            rope_abs_diff=rope_abs_diff if rope_abs_diff is not None else (-0.001, 0.001),\n",
        "            rope_rel_lift=rope_rel_lift if rope_rel_lift is not None else (-0.01, 0.01),\n",
        "            solution_to_compare_idx=solution_to_compare_idx_for_plot\n",
        "        )\n",
        "\n",
        "        console.print(Panel(Text(\"Credible Conversion Rates (95% HDI) - Forest Plot (Plotly chart will render below)\", justify=\"center\"), title=\"[bold]Forest Plot[/bold]\", border_style=\"yellow\", expand=False))\n",
        "        experiment.plot_forest_hdi(metrics)\n",
        "\n",
        "        display_explanations(console)\n",
        "        console.print(\"\\n[bold green]Analysis Complete.[/bold green]\")\n",
        "\n",
        "    except ValueError as ve:\n",
        "        console.print(f\"[bold red]Input Error:[/bold red] {ve}\")\n",
        "    except Exception as e:\n",
        "        console.print(f\"[bold red]An unexpected error occurred:[/bold red] {e}\")\n",
        "        import traceback\n",
        "        console.print(traceback.format_exc())\n",
        "\n",
        "# ^=======================================================================^\n",
        "# |                                                                       |\n",
        "# |    USER'S FULL SCRIPT CONTENT ENDS HERE                               |\n",
        "# |                                                                       |\n",
        "# ^=======================================================================^\n",
        "#\n",
        "\n",
        "#\n",
        "# --- Boilerplate: Display captured output in a tall HTML box ---\n",
        "#\n",
        "sys.stdout = _original_stdout # Restore the original standard output\n",
        "\n",
        "output_content = _captured_output.getvalue() # Get all the content that was \"printed\"\n",
        "\n",
        "_captured_output.close() # Close the StringIO object\n",
        "\n",
        "# Escape the captured output to safely embed it in HTML\n",
        "# This prevents issues if your output contains characters like <, >, &\n",
        "escaped_output = html.escape(output_content)\n",
        "\n",
        "# --- Configuration for the output display ---\n",
        "output_max_height = \"1200px\" # Maximum height for the scrollable text area\n",
        "# Removed min-height property entirely to allow the box to shrink to content size\n",
        "output_bg_color = \"#f9f9f9\"\n",
        "output_border_color = \"#d0d0d0\"\n",
        "output_padding = \"20px\"\n",
        "output_font_size = \"13px\"\n",
        "output_line_height = \"1.6\"\n",
        "\n",
        "# Create the HTML structure\n",
        "# - The outer `div` uses max-height to grow with content up to a limit.\n",
        "# - By omitting min-height, it should shrink to content size (plus padding).\n",
        "# - `overflow-y: auto` enables a vertical scrollbar if content exceeds max-height.\n",
        "# - The inner `<pre>` tag ensures that your output's formatting (line breaks, spaces from rich) is preserved.\n",
        "html_to_display = f\"\"\"\n",
        "<div style=\"max-height: {output_max_height};\n",
        "            overflow-y: auto;\n",
        "            border: 1px solid {output_border_color};\n",
        "            padding: {output_padding};\n",
        "            background-color: {output_bg_color};\n",
        "            border-radius: 8px;\n",
        "            box-shadow: 0 4px 8px rgba(0,0,0,0.05);\n",
        "            \">\n",
        "    <pre style=\"margin: 0;\n",
        "                white-space: pre-wrap; /* Handles rich library's formatting */\n",
        "                word-wrap: break-word;\n",
        "                font-family: 'Menlo', 'Consolas', 'Monaco', 'Liberation Mono', 'Lucida Console', monospace;\n",
        "                font-size: {output_font_size};\n",
        "                line-height: {output_line_height};\n",
        "                color: #333;\n",
        "                \"><code>{escaped_output}</code></pre>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "# Display the HTML in the Colab output area\n",
        "display(HTML(html_to_display))\n",
        "# --- End of output display boilerplate ---\n"
      ],
      "metadata": {
        "id": "lY68zNNzQQHO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}