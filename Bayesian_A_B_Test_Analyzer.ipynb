{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshkellett87/colab-bayesian-calc/blob/main/Bayesian_A_B_Test_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayesian Test Calculator for Online Experiments ðŸ“ˆ\n",
        "Robust a/b/n test calculator created by Josh Kellett.\n",
        "\n",
        "**Instructions**\n",
        "1.   Go to Runtime > Run All to start calc\n",
        "2.   Enter # of test variants\n",
        "3.   Enter priors and set power for control + variants\n",
        "4.   Choose ROPE\n",
        "5.   Add sample & conversion counts for all versions\n",
        "\n",
        "That's it! From there you'll get a detailed analysis of your test results, including decision recommendations and a full set of charts."
      ],
      "metadata": {
        "id": "JQVr_MRgLUmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.panel import Panel\n",
        "from rich.text import Text\n",
        "from rich.padding import Padding\n",
        "from rich.style import Style\n",
        "\n",
        "# Helper function to calculate Highest Density Interval (HDI)\n",
        "def _calculate_hdi(samples, credible_mass=0.95):\n",
        "    \"\"\"Calculate the Highest Density Interval (HDI) for a list of samples.\"\"\"\n",
        "    if samples is None or len(samples) == 0:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    samples = samples[~np.isnan(samples)]\n",
        "    if len(samples) == 0:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    sorted_samples = np.sort(samples)\n",
        "    n_samples = len(samples)\n",
        "\n",
        "    interval_idx_inc = int(np.floor(credible_mass * n_samples))\n",
        "    if interval_idx_inc == 0:\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    n_intervals = n_samples - interval_idx_inc\n",
        "    if n_intervals <= 0:\n",
        "         return (sorted_samples[0], sorted_samples[-1])\n",
        "\n",
        "    interval_width = sorted_samples[interval_idx_inc:] - sorted_samples[:n_intervals]\n",
        "\n",
        "    if len(interval_width) == 0:\n",
        "        return (sorted_samples[0], sorted_samples[-1])\n",
        "\n",
        "    min_idx = np.argmin(interval_width)\n",
        "    hdi_min = sorted_samples[min_idx]\n",
        "    hdi_max = sorted_samples[min_idx + interval_idx_inc]\n",
        "    return hdi_min, hdi_max\n",
        "\n",
        "class BayesianExperiment:\n",
        "    \"\"\"\n",
        "    A class to perform Bayesian analysis for an A/B test with binomial data,\n",
        "    supporting multiple solution variants.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_solution_variants=1):\n",
        "        if not isinstance(num_solution_variants, int) or num_solution_variants < 1:\n",
        "            raise ValueError(\"Number of solution variants must be a positive integer.\")\n",
        "        self.num_solution_variants = num_solution_variants\n",
        "\n",
        "        # Control parameters\n",
        "        self.control_prior_alpha = 1.0\n",
        "        self.control_prior_beta = 1.0\n",
        "        self.control_posterior_alpha = 1.0\n",
        "        self.control_posterior_beta = 1.0\n",
        "        self.control_samples = 0\n",
        "        self.control_conversions = 0\n",
        "        self.control_observed_alpha_likelihood = 1\n",
        "        self.control_observed_beta_likelihood = 1\n",
        "\n",
        "        # Solution variant parameters (lists)\n",
        "        self.solution_prior_alpha = [1.0] * num_solution_variants\n",
        "        self.solution_prior_beta = [1.0] * num_solution_variants\n",
        "        self.solution_posterior_alpha = [1.0] * num_solution_variants\n",
        "        self.solution_posterior_beta = [1.0] * num_solution_variants\n",
        "        self.solution_samples = [0] * num_solution_variants\n",
        "        self.solution_conversions = [0] * num_solution_variants\n",
        "        self.solution_observed_alpha_likelihood = [1] * num_solution_variants\n",
        "        self.solution_observed_beta_likelihood = [1] * num_solution_variants\n",
        "\n",
        "        self.variant_names = [\"Control\"] + [f\"Solution {i+1}\" for i in range(num_solution_variants)]\n",
        "\n",
        "\n",
        "    def set_priors(self, control_alpha, control_beta, solution_alphas, solution_betas):\n",
        "        if control_alpha <= 0 or control_beta <= 0:\n",
        "            raise ValueError(\"Control prior alpha and beta parameters must be positive.\")\n",
        "        if not (isinstance(solution_alphas, list) and isinstance(solution_betas, list) and\n",
        "                len(solution_alphas) == self.num_solution_variants and len(solution_betas) == self.num_solution_variants):\n",
        "            raise ValueError(f\"Solution priors must be lists of length {self.num_solution_variants}.\")\n",
        "        for sa, sb in zip(solution_alphas, solution_betas):\n",
        "            if sa <= 0 or sb <= 0:\n",
        "                raise ValueError(\"Solution prior alpha and beta parameters must be positive.\")\n",
        "\n",
        "        self.control_prior_alpha = control_alpha\n",
        "        self.control_prior_beta = control_beta\n",
        "        self.control_posterior_alpha = control_alpha\n",
        "        self.control_posterior_beta = control_beta\n",
        "\n",
        "        self.solution_prior_alpha = list(solution_alphas)\n",
        "        self.solution_prior_beta = list(solution_betas)\n",
        "        self.solution_posterior_alpha = list(solution_alphas)\n",
        "        self.solution_posterior_beta = list(solution_betas)\n",
        "\n",
        "\n",
        "    def update_results(self, control_samples, control_conversions, solution_samples_list, solution_conversions_list):\n",
        "        if control_samples < control_conversions or control_samples < 0:\n",
        "            raise ValueError(\"Control samples must be non-negative and >= control conversions.\")\n",
        "        if not (isinstance(solution_samples_list, list) and isinstance(solution_conversions_list, list) and\n",
        "                len(solution_samples_list) == self.num_solution_variants and len(solution_conversions_list) == self.num_solution_variants):\n",
        "            raise ValueError(f\"Solution results must be lists of length {self.num_solution_variants}.\")\n",
        "\n",
        "        self.control_samples = control_samples\n",
        "        self.control_conversions = control_conversions\n",
        "        control_losses = control_samples - control_conversions\n",
        "        self.control_posterior_alpha = self.control_prior_alpha + control_conversions\n",
        "        self.control_posterior_beta = self.control_prior_beta + control_losses\n",
        "        self.control_observed_alpha_likelihood = control_conversions + (1 if control_conversions == 0 and control_losses == 0 else 0)\n",
        "        self.control_observed_beta_likelihood = control_losses + (1 if control_conversions == 0 and control_losses == 0 else 0)\n",
        "\n",
        "        for i in range(self.num_solution_variants):\n",
        "            s_samples = solution_samples_list[i]\n",
        "            s_conversions = solution_conversions_list[i]\n",
        "            if s_samples < s_conversions or s_samples < 0:\n",
        "                raise ValueError(f\"Solution {i+1} samples must be non-negative and >= conversions.\")\n",
        "            if s_conversions < 0:\n",
        "                raise ValueError(f\"Solution {i+1} conversions must be non-negative.\")\n",
        "\n",
        "            self.solution_samples[i] = s_samples\n",
        "            self.solution_conversions[i] = s_conversions\n",
        "            s_losses = s_samples - s_conversions\n",
        "            self.solution_posterior_alpha[i] = self.solution_prior_alpha[i] + s_conversions\n",
        "            self.solution_posterior_beta[i] = self.solution_prior_beta[i] + s_losses\n",
        "            self.solution_observed_alpha_likelihood[i] = s_conversions + (1 if s_conversions == 0 and s_losses == 0 else 0)\n",
        "            self.solution_observed_beta_likelihood[i] = s_losses + (1 if s_conversions == 0 and s_losses == 0 else 0)\n",
        "\n",
        "\n",
        "    def get_posterior_samples(self, n_samples=20000):\n",
        "        \"\"\"Generates posterior samples for control and all solution variants.\"\"\"\n",
        "        all_samples = {}\n",
        "        all_samples['control_rate'] = stats.beta.rvs(\n",
        "            self.control_posterior_alpha, self.control_posterior_beta, size=n_samples\n",
        "        )\n",
        "        for i in range(self.num_solution_variants):\n",
        "            variant_name = f\"solution_{i+1}_rate\"\n",
        "            all_samples[variant_name] = stats.beta.rvs(\n",
        "                self.solution_posterior_alpha[i], self.solution_posterior_beta[i], size=n_samples\n",
        "            )\n",
        "\n",
        "        for i in range(self.num_solution_variants):\n",
        "            all_samples[f\"abs_diff_s{i+1}_c\"] = all_samples[f\"solution_{i+1}_rate\"] - all_samples['control_rate']\n",
        "\n",
        "        for i in range(self.num_solution_variants):\n",
        "            rel_lift_samples = np.full_like(all_samples['control_rate'], np.nan)\n",
        "            valid_mask = all_samples['control_rate'] > 1e-9\n",
        "            rel_lift_samples[valid_mask] = (all_samples[f\"solution_{i+1}_rate\"][valid_mask] - all_samples['control_rate'][valid_mask]) / all_samples['control_rate'][valid_mask]\n",
        "            all_samples[f\"rel_lift_s{i+1}_c\"] = rel_lift_samples\n",
        "\n",
        "        return all_samples\n",
        "\n",
        "    def calculate_metrics(self, rope_abs_diff=(-0.005, 0.005), rope_rel_lift=(-0.05, 0.05),\n",
        "                          prob_beat_threshold=0.0, credible_mass=0.95, n_samples_for_calc=20000):\n",
        "        \"\"\"Calculates metrics for control and all solution variants.\"\"\"\n",
        "        samples = self.get_posterior_samples(n_samples=n_samples_for_calc)\n",
        "        metrics = {'control': {}, 'solutions': [{} for _ in range(self.num_solution_variants)]}\n",
        "\n",
        "        control_s = samples['control_rate']\n",
        "        metrics['control']['posterior_mean_rate'] = np.mean(control_s)\n",
        "        metrics['control']['rate_hdi'] = _calculate_hdi(control_s, credible_mass)\n",
        "\n",
        "        all_variant_samples = [samples['control_rate']]\n",
        "        for i in range(self.num_solution_variants):\n",
        "            sol_s = samples[f\"solution_{i+1}_rate\"]\n",
        "            abs_diff_s = samples[f\"abs_diff_s{i+1}_c\"]\n",
        "            rel_lift_s = samples[f\"rel_lift_s{i+1}_c\"][~np.isnan(samples[f\"rel_lift_s{i+1}_c\"])]\n",
        "\n",
        "            metrics['solutions'][i]['name'] = f\"Solution {i+1}\"\n",
        "            metrics['solutions'][i]['posterior_mean_rate'] = np.mean(sol_s)\n",
        "            metrics['solutions'][i]['rate_hdi'] = _calculate_hdi(sol_s, credible_mass)\n",
        "\n",
        "            metrics['solutions'][i]['absolute_difference_mean'] = np.mean(abs_diff_s)\n",
        "            metrics['solutions'][i]['absolute_difference_hdi'] = _calculate_hdi(abs_diff_s, credible_mass)\n",
        "\n",
        "            if len(rel_lift_s) > 0:\n",
        "                metrics['solutions'][i]['relative_lift_mean'] = np.mean(rel_lift_s)\n",
        "                metrics['solutions'][i]['relative_lift_hdi'] = _calculate_hdi(rel_lift_s, credible_mass)\n",
        "            else:\n",
        "                metrics['solutions'][i]['relative_lift_mean'] = np.nan\n",
        "                metrics['solutions'][i]['relative_lift_hdi'] = (np.nan, np.nan)\n",
        "\n",
        "            metrics['solutions'][i]['prob_beats_control'] = np.mean(sol_s > control_s)\n",
        "            metrics['solutions'][i]['prob_beats_control_by_threshold'] = np.mean(sol_s > (control_s + prob_beat_threshold))\n",
        "\n",
        "            metrics['solutions'][i]['prob_abs_diff_below_rope'] = np.mean(abs_diff_s < rope_abs_diff[0])\n",
        "            metrics['solutions'][i]['prob_abs_diff_in_rope'] = np.mean((abs_diff_s >= rope_abs_diff[0]) & (abs_diff_s <= rope_abs_diff[1]))\n",
        "            metrics['solutions'][i]['prob_abs_diff_above_rope'] = np.mean(abs_diff_s > rope_abs_diff[1])\n",
        "\n",
        "            if len(rel_lift_s) > 0:\n",
        "                metrics['solutions'][i]['prob_rel_lift_below_rope'] = np.mean(rel_lift_s < rope_rel_lift[0])\n",
        "                metrics['solutions'][i]['prob_rel_lift_in_rope'] = np.mean((rel_lift_s >= rope_rel_lift[0]) & (rel_lift_s <= rope_rel_lift[1]))\n",
        "                metrics['solutions'][i]['prob_rel_lift_above_rope'] = np.mean(rel_lift_s > rope_rel_lift[1])\n",
        "            else:\n",
        "                for key in ['prob_rel_lift_below_rope', 'prob_rel_lift_in_rope', 'prob_rel_lift_above_rope']:\n",
        "                    metrics['solutions'][i][key] = np.nan\n",
        "\n",
        "            metrics['solutions'][i]['expected_loss_vs_control_choosing_solution'] = np.mean(np.maximum(0, control_s - sol_s))\n",
        "            metrics['solutions'][i]['expected_loss_vs_control_choosing_control'] = np.mean(np.maximum(0, sol_s - control_s))\n",
        "\n",
        "            all_variant_samples.append(sol_s)\n",
        "\n",
        "        stacked_samples = np.stack(all_variant_samples, axis=-1)\n",
        "        best_variant_indices = np.argmax(stacked_samples, axis=1)\n",
        "\n",
        "        metrics['prob_control_is_best'] = np.mean(best_variant_indices == 0)\n",
        "        for i in range(self.num_solution_variants):\n",
        "            metrics['solutions'][i]['prob_is_best'] = np.mean(best_variant_indices == (i + 1))\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def get_decision_summary(self, metrics, rope_abs_diff_vs_control, p_threshold=0.95, loss_ratio_threshold=5):\n",
        "        \"\"\"Generates a decision summary for multiple variants.\"\"\"\n",
        "        best_overall_prob = metrics.get('prob_control_is_best', 0.0)\n",
        "        best_variant_idx = -1\n",
        "\n",
        "        for i, sol_metrics in enumerate(metrics['solutions']):\n",
        "            if sol_metrics.get('prob_is_best', 0.0) > best_overall_prob:\n",
        "                best_overall_prob = sol_metrics.get('prob_is_best', 0.0)\n",
        "                best_variant_idx = i\n",
        "\n",
        "        if best_variant_idx == -1:\n",
        "            evaluation = \"Control is Most Likely Best\"\n",
        "            recommendation = \"Stick with Control\"\n",
        "            rec_style = \"blue\"\n",
        "            for i, sol_metrics in enumerate(metrics['solutions']):\n",
        "                 prob_s_beats_c = sol_metrics.get('prob_beats_control', 0.0)\n",
        "                 loss_ctrl_vs_sol = sol_metrics.get('expected_loss_vs_control_choosing_control', np.inf)\n",
        "                 loss_sol_vs_ctrl = sol_metrics.get('expected_loss_vs_control_choosing_solution', np.inf)\n",
        "                 if prob_s_beats_c > 0.90 and loss_ctrl_vs_sol > loss_sol_vs_ctrl * (loss_ratio_threshold / 2):\n",
        "                      recommendation += f\" (Consider Solution {i+1} if P(Best) for Control is marginal and risk is acceptable)\"\n",
        "                      break\n",
        "            return evaluation, recommendation, rec_style\n",
        "\n",
        "        best_sol_metrics = metrics['solutions'][best_variant_idx]\n",
        "        evaluation = f\"Solution {best_variant_idx+1} is Most Likely Best (P(Best)={best_sol_metrics.get('prob_is_best',0):.1%})\"\n",
        "\n",
        "        hdi_low, hdi_high = best_sol_metrics.get('absolute_difference_hdi', (np.nan, np.nan))\n",
        "        rope_low, rope_high = rope_abs_diff_vs_control\n",
        "        prob_s_beats_c = best_sol_metrics.get('prob_beats_control', 0.0)\n",
        "        loss_ctrl_vs_sol = best_sol_metrics.get('expected_loss_vs_control_choosing_control', np.inf)\n",
        "        loss_sol_vs_ctrl = best_sol_metrics.get('expected_loss_vs_control_choosing_solution', np.inf)\n",
        "\n",
        "        if np.isnan(hdi_low) or np.isnan(hdi_high):\n",
        "            return evaluation, f\"Error calculating HDI for Solution {best_variant_idx+1}\", \"red\"\n",
        "\n",
        "        if hdi_low > rope_high:\n",
        "            recommendation = f\"Accept Solution {best_variant_idx+1} (Clear Win vs Control)\"\n",
        "            rec_style = \"green\"\n",
        "        elif hdi_high < rope_low:\n",
        "            recommendation = f\"Review Solution {best_variant_idx+1} (Likely best but worse than Control within ROPE)\"\n",
        "            rec_style = \"red\"\n",
        "        elif hdi_low >= rope_low and hdi_high <= rope_high:\n",
        "            if prob_s_beats_c > 0.99 and loss_ctrl_vs_sol > loss_sol_vs_ctrl * loss_ratio_threshold :\n",
        "                 recommendation = f\"Accept Solution {best_variant_idx+1} (Practically Equivalent to Control but High Confidence & Favorable Risk)\"\n",
        "                 rec_style = \"green\"\n",
        "            else:\n",
        "                recommendation = f\"Solution {best_variant_idx+1} is Likely Best but Practically Equivalent to Control\"\n",
        "                rec_style = \"blue\"\n",
        "        else:\n",
        "            recommendation = f\"Accept Solution {best_variant_idx+1} (Strong Candidate)\"\n",
        "            rec_style = \"yellow\"\n",
        "            if prob_s_beats_c >= p_threshold and loss_ctrl_vs_sol > loss_sol_vs_ctrl * loss_ratio_threshold:\n",
        "                recommendation = f\"Accept Solution {best_variant_idx+1} (High P(>C) & Favorable Risk, despite ROPE overlap)\"\n",
        "                rec_style = \"green\"\n",
        "\n",
        "        return evaluation, recommendation, rec_style\n",
        "\n",
        "    def _get_dynamic_axis_range(self, *distributions_params_or_samples,\n",
        "                                percentile_low=0.01, percentile_high=99.99,\n",
        "                                padding_factor=0.08, allow_negative=False):\n",
        "        all_quantiles = np.array([])\n",
        "        for item in distributions_params_or_samples:\n",
        "            if item is None: continue\n",
        "            if isinstance(item, tuple) and len(item) == 2:\n",
        "                alpha, beta = item\n",
        "                if alpha > 0 and beta > 0:\n",
        "                    q_low = stats.beta.ppf(percentile_low / 100.0, alpha, beta)\n",
        "                    q_high = stats.beta.ppf(percentile_high / 100.0, alpha, beta)\n",
        "                    if not np.isnan(q_low) and not np.isnan(q_high):\n",
        "                         all_quantiles = np.concatenate([all_quantiles, [q_low, q_high]])\n",
        "            elif isinstance(item, np.ndarray) and item.size > 0:\n",
        "                valid_samples = item[~np.isnan(item)]\n",
        "                if valid_samples.size > 0:\n",
        "                    q_low = np.percentile(valid_samples, percentile_low)\n",
        "                    q_high = np.percentile(valid_samples, percentile_high)\n",
        "                    all_quantiles = np.concatenate([all_quantiles, [q_low, q_high]])\n",
        "        if all_quantiles.size == 0:\n",
        "            return (0.0, 0.1) if not allow_negative else (-0.05, 0.05)\n",
        "        min_val = np.min(all_quantiles)\n",
        "        max_val = np.max(all_quantiles)\n",
        "        current_range = max_val - min_val\n",
        "        if current_range < 1e-6:\n",
        "            padding = 0.005\n",
        "        else:\n",
        "            padding = current_range * padding_factor\n",
        "        axis_min = min_val - padding\n",
        "        if not allow_negative:\n",
        "            axis_min = max(0.0, axis_min)\n",
        "        axis_max = max_val + padding\n",
        "        if not allow_negative:\n",
        "             axis_max = min(1.0, axis_max)\n",
        "        if axis_max <= axis_min:\n",
        "             axis_max = axis_min + (0.001 if not allow_negative else 0.0001 * abs(axis_min) + 0.0001)\n",
        "        if not allow_negative and axis_max > 1.0: axis_max = 1.0\n",
        "        if not allow_negative and axis_min < 0.0: axis_min = 0.0\n",
        "        return axis_min, axis_max\n",
        "\n",
        "\n",
        "    def plot_distributions_plotly(self, rope_abs_diff=(-0.005, 0.005), rope_rel_lift=(-0.05, 0.05),\n",
        "                                  n_samples_for_plot=10000):\n",
        "        \"\"\"\n",
        "        Generate and display interactive plots for multiple variants.\n",
        "        \"\"\"\n",
        "        samples_data = self.get_posterior_samples(n_samples=n_samples_for_plot)\n",
        "        control_post_s = samples_data['control_rate']\n",
        "\n",
        "        solution_line_colors = ['lightcoral', 'lightseagreen', 'mediumpurple', 'gold']\n",
        "        solution_fill_colors = [\n",
        "            'rgba(240,128,128,0.4)',\n",
        "            'rgba(32,178,170,0.4)',\n",
        "            'rgba(147,112,219,0.4)',\n",
        "            'rgba(255,215,0,0.4)'\n",
        "        ]\n",
        "\n",
        "        metrics_temp = self.calculate_metrics(rope_abs_diff, rope_rel_lift)\n",
        "        best_sol_idx = -1\n",
        "        max_p_best = metrics_temp.get('prob_control_is_best', 0.0)\n",
        "        best_sol_name_for_title = \"Solution 1\"\n",
        "        if self.num_solution_variants > 0:\n",
        "            best_sol_name_for_title = metrics_temp['solutions'][0]['name']\n",
        "\n",
        "        for i, sol_metrics in enumerate(metrics_temp['solutions']):\n",
        "            if sol_metrics.get('prob_is_best', 0.0) > max_p_best:\n",
        "                max_p_best = sol_metrics.get('prob_is_best', 0.0)\n",
        "                best_sol_idx = i\n",
        "                best_sol_name_for_title = sol_metrics['name']\n",
        "        if best_sol_idx == -1 and self.num_solution_variants > 0:\n",
        "            best_sol_name_for_title = metrics_temp['solutions'][0]['name']\n",
        "        elif best_sol_idx == -1 and self.num_solution_variants == 0:\n",
        "            best_sol_name_for_title = \"Solution\"\n",
        "\n",
        "\n",
        "        fig = make_subplots(\n",
        "            rows=3, cols=2,\n",
        "            subplot_titles=(\n",
        "                \"<b>Prior Distributions</b>\",\n",
        "                \"<b>Observed Data Likelihoods</b>\",\n",
        "                \"<b>Posterior Distributions</b>\",\n",
        "                f\"<b>Which Variant is Most Likely the Winner?</b>\",\n",
        "                f\"<b>Absolute Difference: {best_sol_name_for_title} vs. Control</b>\",\n",
        "                f\"<b>Probability of {best_sol_name_for_title} Beating Control by > X% (Relative Lift)</b>\"\n",
        "            ),\n",
        "            specs=[[{}, {}],\n",
        "                   [{}, {}],\n",
        "                   [{}, {}]],\n",
        "            vertical_spacing=0.15,\n",
        "            horizontal_spacing=0.1\n",
        "        )\n",
        "\n",
        "        all_prior_params = [(self.control_prior_alpha, self.control_prior_beta)] + \\\n",
        "                           [(self.solution_prior_alpha[i], self.solution_prior_beta[i]) for i in range(self.num_solution_variants)]\n",
        "        prior_min_x, prior_max_x = self._get_dynamic_axis_range(*all_prior_params, allow_negative=False)\n",
        "        x_prior_plot = np.linspace(prior_min_x, prior_max_x, 200)\n",
        "\n",
        "        all_like_params = [(self.control_observed_alpha_likelihood, self.control_observed_beta_likelihood) if self.control_samples > 0 else None] + \\\n",
        "                          [(self.solution_observed_alpha_likelihood[i], self.solution_observed_beta_likelihood[i]) if self.solution_samples[i] > 0 else None for i in range(self.num_solution_variants)]\n",
        "        like_min_x, like_max_x = self._get_dynamic_axis_range(*[p for p in all_like_params if p is not None], allow_negative=False)\n",
        "        x_like_plot = np.linspace(like_min_x, like_max_x, 200)\n",
        "\n",
        "        all_post_samples = [control_post_s] + [samples_data[f\"solution_{i+1}_rate\"] for i in range(self.num_solution_variants)]\n",
        "        post_min_x, post_max_x = self._get_dynamic_axis_range(*[s for s in all_post_samples if len(s) > 0], allow_negative=False)\n",
        "        x_post_plot = np.linspace(post_min_x, post_max_x, 200)\n",
        "\n",
        "        # Plot 1: Prior Distributions\n",
        "        fig.add_trace(go.Scatter(x=x_prior_plot, y=stats.beta.pdf(x_prior_plot, self.control_prior_alpha, self.control_prior_beta),\n",
        "                                 mode='lines', name='Ctrl Prior', legendgroup=\"Priors\", line=dict(dash='dash', color='skyblue', width=2),\n",
        "                                 hovertemplate=\"<b>Ctrl Prior</b><br>Rate: %{x:.3%}<br>Density: %{y:.2f}<extra></extra>\"), row=1, col=1)\n",
        "        for i in range(self.num_solution_variants):\n",
        "            fig.add_trace(go.Scatter(x=x_prior_plot, y=stats.beta.pdf(x_prior_plot, self.solution_prior_alpha[i], self.solution_prior_beta[i]),\n",
        "                                     mode='lines', name=f'Sol {i+1} Prior', legendgroup=\"Priors\",\n",
        "                                     line=dict(dash='dash', color=solution_line_colors[i % len(solution_line_colors)], width=2),\n",
        "                                     hovertemplate=f\"<b>Sol {i+1} Prior</b><br>Rate: %{{x:.3%}}<br>Density: %{{y:.2f}}<extra></extra>\"), row=1, col=1)\n",
        "        fig.update_xaxes(range=[prior_min_x, prior_max_x], row=1, col=1)\n",
        "\n",
        "        # Plot 2: Observed Data Likelihoods\n",
        "        if self.control_samples > 0:\n",
        "            fig.add_trace(go.Scatter(x=x_like_plot, y=stats.beta.pdf(x_like_plot, self.control_observed_alpha_likelihood, self.control_observed_beta_likelihood),\n",
        "                                     mode='lines', name='Ctrl Likelihood', legendgroup=\"Likelihoods\", line=dict(dash='dot', color='lightgreen', width=2),\n",
        "                                     hovertemplate=\"<b>Ctrl Likelihood</b><br>Rate: %{x:.3%}<br>Density: %{y:.2f}<extra></extra>\"), row=1, col=2)\n",
        "        for i in range(self.num_solution_variants):\n",
        "            if self.solution_samples[i] > 0:\n",
        "                fig.add_trace(go.Scatter(x=x_like_plot, y=stats.beta.pdf(x_like_plot, self.solution_observed_alpha_likelihood[i], self.solution_observed_beta_likelihood[i]),\n",
        "                                         mode='lines', name=f'Sol {i+1} Likelihood', legendgroup=\"Likelihoods\",\n",
        "                                         line=dict(dash='dot', color=solution_line_colors[i % len(solution_line_colors)], width=1.5),\n",
        "                                         opacity=0.8,\n",
        "                                         hovertemplate=f\"<b>Sol {i+1} Likelihood</b><br>Rate: %{{x:.3%}}<br>Density: %{{y:.2f}}<extra></extra>\"), row=1, col=2)\n",
        "        if self.control_samples == 0 and all(s == 0 for s in self.solution_samples):\n",
        "             fig.add_annotation(text=\"No observed data entered\", showarrow=False, row=1, col=2)\n",
        "        fig.update_xaxes(range=[like_min_x, like_max_x], row=1, col=2)\n",
        "\n",
        "        # Plot 3: Posterior Distributions\n",
        "        max_density_post = 0\n",
        "        if len(control_post_s) > 1:\n",
        "            kde_control = stats.gaussian_kde(control_post_s)\n",
        "            y_kde_control = kde_control(x_post_plot)\n",
        "            max_density_post = max(max_density_post, np.max(y_kde_control))\n",
        "            fig.add_trace(go.Scatter(x=x_post_plot, y=y_kde_control, mode='lines', name='Ctrl Posterior', legendgroup=\"Posteriors\", fill='tozeroy',\n",
        "                                     fillcolor='rgba(70,130,180,0.4)', line=dict(color='steelblue', width=2),\n",
        "                                     hovertemplate=\"<b>Ctrl Posterior</b><br>Rate: %{x:.3%}<br>Density: %{y:.2f}<extra></extra>\"), row=2, col=1)\n",
        "        for i in range(self.num_solution_variants):\n",
        "            sol_s = samples_data[f\"solution_{i+1}_rate\"]\n",
        "            if len(sol_s) > 1:\n",
        "                kde_solution = stats.gaussian_kde(sol_s)\n",
        "                y_kde_solution = kde_solution(x_post_plot)\n",
        "                max_density_post = max(max_density_post, np.max(y_kde_solution))\n",
        "                fig.add_trace(go.Scatter(x=x_post_plot, y=y_kde_solution, mode='lines', name=f'Sol {i+1} Posterior', legendgroup=\"Posteriors\", fill='tozeroy',\n",
        "                                         fillcolor=solution_fill_colors[i % len(solution_fill_colors)],\n",
        "                                         line=dict(color=solution_line_colors[i % len(solution_line_colors)], width=2),\n",
        "                                         hovertemplate=f\"<b>Sol {i+1} Posterior</b><br>Rate: %{{x:.3%}}<br>Density: %{{y:.2f}}<extra></extra>\"), row=2, col=1)\n",
        "        fig.update_xaxes(range=[post_min_x, post_max_x], row=2, col=1)\n",
        "\n",
        "        # Plot 4: Probability of Being Best\n",
        "        prob_best_names = [self.variant_names[0]] + [sol_metrics['name'] for sol_metrics in metrics_temp['solutions']]\n",
        "        prob_best_values = [metrics_temp.get('prob_control_is_best', 0)] + [sol_metrics.get('prob_is_best', 0) for sol_metrics in metrics_temp['solutions']]\n",
        "        bar_colors = ['skyblue'] + [solution_line_colors[i % len(solution_line_colors)] for i in range(self.num_solution_variants)]\n",
        "        fig.add_trace(go.Bar(x=prob_best_names, y=prob_best_values, name='P(Best)', legendgroup=\"P(Best)\",\n",
        "                             marker_color=bar_colors, text=[f\"{p:.1%}\" for p in prob_best_values], textposition='auto',\n",
        "                             hovertemplate=\"<b>%{x}</b><br>P(Best): %{y:.2%}<extra></extra>\"), row=2, col=2)\n",
        "        fig.update_yaxes(tickformat=\".0%\", range=[0,1.05], row=2, col=2)\n",
        "\n",
        "        # Plot 5: Difference (Best Solution vs Control)\n",
        "        best_sol_abs_diff_s = np.array([])\n",
        "        if best_sol_idx != -1:\n",
        "            best_sol_abs_diff_s = samples_data[f\"abs_diff_s{best_sol_idx+1}_c\"]\n",
        "        elif self.num_solution_variants > 0 :\n",
        "            best_sol_abs_diff_s = samples_data.get(f\"abs_diff_s1_c\", np.array([]))\n",
        "\n",
        "        if len(best_sol_abs_diff_s) > 1:\n",
        "            diff_min_x, diff_max_x = self._get_dynamic_axis_range(best_sol_abs_diff_s, allow_negative=True)\n",
        "            x_diff_plot = np.linspace(diff_min_x, diff_max_x, 200)\n",
        "            kde_abs_diff = stats.gaussian_kde(best_sol_abs_diff_s)\n",
        "            y_kde_abs_diff = kde_abs_diff(x_diff_plot)\n",
        "            fig.add_trace(go.Scatter(x=x_diff_plot, y=y_kde_abs_diff, mode='lines', name='Abs. Diff (Best Sol)', legendgroup=\"Difference Analysis\", fill='tozeroy',\n",
        "                                     fillcolor='rgba(128,0,128,0.4)', line=dict(color='purple', width=2),\n",
        "                                     hovertemplate=\"<b>Abs. Difference</b><br>Value: %{x:.3%}<br>Density: %{y:.2f}<extra></extra>\"), row=3, col=1)\n",
        "            abs_diff_mean = np.mean(best_sol_abs_diff_s)\n",
        "            abs_diff_hdi = _calculate_hdi(best_sol_abs_diff_s)\n",
        "            fig.add_vline(x=abs_diff_mean, line_width=1.5, line_dash=\"dash\", line_color=\"indigo\", row=3, col=1)\n",
        "            fig.add_vline(x=abs_diff_hdi[0], line_width=1.5, line_dash=\"dot\", line_color=\"indigo\", row=3, col=1)\n",
        "            fig.add_vline(x=abs_diff_hdi[1], line_width=1.5, line_dash=\"dot\", line_color=\"indigo\", row=3, col=1)\n",
        "            fig.add_shape(type=\"rect\", x0=rope_abs_diff[0], x1=rope_abs_diff[1], y0=0, y1=np.max(y_kde_abs_diff)*1.1 if len(y_kde_abs_diff) > 0 else 1,\n",
        "                          fillcolor=\"rgba(169,169,169,0.3)\", opacity=0.3, layer=\"below\", line_width=0, name=\"ROPE Abs.Diff.\", row=3, col=1)\n",
        "            fig.update_xaxes(range=[diff_min_x, diff_max_x], row=3, col=1)\n",
        "\n",
        "        # Plot 6: Cumulative P(Best Solution Relative Uplift > X)\n",
        "        best_sol_rel_lift_s = np.array([])\n",
        "        if best_sol_idx != -1:\n",
        "            best_sol_rel_lift_s = samples_data[f\"rel_lift_s{best_sol_idx+1}_c\"][~np.isnan(samples_data[f\"rel_lift_s{best_sol_idx+1}_c\"])]\n",
        "        elif self.num_solution_variants > 0:\n",
        "            best_sol_rel_lift_s = samples_data.get(f\"rel_lift_s1_c\", np.array([]))\n",
        "            best_sol_rel_lift_s = best_sol_rel_lift_s[~np.isnan(best_sol_rel_lift_s)]\n",
        "\n",
        "        if len(best_sol_rel_lift_s) > 0:\n",
        "            cum_rel_min_x, cum_rel_max_x = self._get_dynamic_axis_range(best_sol_rel_lift_s, allow_negative=True)\n",
        "            sorted_rel_lift = np.sort(best_sol_rel_lift_s)\n",
        "            y_cumulative_rel = 1. - (np.arange(len(sorted_rel_lift)) / float(len(sorted_rel_lift)))\n",
        "            fig.add_trace(go.Scatter(x=sorted_rel_lift, y=y_cumulative_rel, mode='lines', name='P(Rel. Uplift > X)', legendgroup=\"Cumulative Uplift\", line=dict(color='darkcyan', width=2),\n",
        "                                     hovertemplate=\"<b>P(Rel. Uplift > X)</b><br>Rel. Uplift (X): %{x:.2%}<br>Probability: %{y:.2%}<extra></extra>\"), row=3, col=2)\n",
        "            fig.add_hline(y=0.95, line_width=1, line_dash=\"dash\", line_color=\"gray\", row=3, col=2)\n",
        "            fig.add_hline(y=0.50, line_width=1, line_dash=\"dot\", line_color=\"gray\", row=3, col=2)\n",
        "            fig.add_vline(x=0, line_width=1, line_dash=\"solid\", line_color=\"black\", row=3, col=2)\n",
        "            fig.update_xaxes(range=[cum_rel_min_x, cum_rel_max_x], row=3, col=2)\n",
        "            fig.update_yaxes(range=[0,1.05], row=3, col=2)\n",
        "        else:\n",
        "             fig.add_annotation(text=\"Not enough data for Cumulative Rel. Uplift\", showarrow=False, row=3, col=2)\n",
        "\n",
        "        fig.update_layout(\n",
        "            height=1200,\n",
        "            title_text=\"<b>Bayesian A/B Test Visualizations</b>\", title_x=0.5, title_font_size=20,\n",
        "            legend_traceorder='grouped', legend_tracegroupgap=15, hovermode='x unified', template='plotly_white'\n",
        "        )\n",
        "        for r,c in [(1,1),(1,2),(2,1),(2,2),(3,1),(3,2)]: fig.update_xaxes(tickformat=\".2%\", row=r, col=c)\n",
        "        for r,c in [(1,1),(1,2),(2,1),(3,1),(3,2)]: fig.update_yaxes(title_text=\"Density\", row=r, col=c)\n",
        "        fig.update_yaxes(title_text=\"Probability P(Best)\", tickformat=\".0%\", row=2, col=2)\n",
        "        fig.update_yaxes(title_text=\"Probability P(Rel. Uplift > X)\", tickformat=\".0%\", row=3, col=2)\n",
        "\n",
        "        fig.show()\n",
        "\n",
        "# --- Display Helper Functions ---\n",
        "# ... (No changes to display functions)\n",
        "def display_test_outcomes_table(console, metrics):\n",
        "    \"\"\"Displays the Test Outcomes table for multiple variants.\"\"\"\n",
        "    table = Table(title=\"Test Outcomes Summary\", title_style=\"bold magenta\", border_style=\"blue\")\n",
        "    table.add_column(\"Group\", style=\"cyan\")\n",
        "    table.add_column(\"Win Rate (Mean)\", style=\"dim\")\n",
        "    table.add_column(\"Rel. Lift vs Ctrl (Mean)\", style=\"dim\")\n",
        "    table.add_column(\"95% HDI (Rate)\", style=\"dim\")\n",
        "\n",
        "    # Control Row\n",
        "    c_metrics = metrics['control']\n",
        "    table.add_row(\"Control\", f\"{c_metrics['posterior_mean_rate']:.2%}\", \"N/A\", f\"[{c_metrics['rate_hdi'][0]:.2%}, {c_metrics['rate_hdi'][1]:.2%}]\")\n",
        "\n",
        "    # Solution Variant Rows\n",
        "    for sol_metrics in metrics['solutions']:\n",
        "        rl_mean = sol_metrics.get('relative_lift_mean', np.nan)\n",
        "        table.add_row(\n",
        "            sol_metrics['name'],\n",
        "            f\"{sol_metrics['posterior_mean_rate']:.2%}\",\n",
        "            f\"{rl_mean:+.2%}\" if not np.isnan(rl_mean) else \"N/A\",\n",
        "            f\"[{sol_metrics['rate_hdi'][0]:.2%}, {sol_metrics['rate_hdi'][1]:.2%}]\"\n",
        "        )\n",
        "    console.print(Padding(table, (1, 0)))\n",
        "\n",
        "\n",
        "def display_confidence_intervals_summary(console, metrics):\n",
        "    \"\"\"Displays a dedicated summary of key confidence intervals for multiple variants.\"\"\"\n",
        "    panel_content = Text()\n",
        "    # Control\n",
        "    c_metrics = metrics['control']\n",
        "    panel_content.append(\"Control Conversion Rate:\\n\", style=\"bold sky_blue3\")\n",
        "    panel_content.append(f\"  Mean: {c_metrics['posterior_mean_rate']:.2%}, 95% HDI: [{c_metrics['rate_hdi'][0]:.2%}, {c_metrics['rate_hdi'][1]:.2%}]\\n\\n\")\n",
        "\n",
        "    # Solution Variants\n",
        "    for sol_metrics in metrics['solutions']:\n",
        "        panel_content.append(f\"{sol_metrics['name']} Conversion Rate:\\n\", style=\"bold light_coral\")\n",
        "        panel_content.append(f\"  Mean: {sol_metrics['posterior_mean_rate']:.2%}, 95% HDI: [{sol_metrics['rate_hdi'][0]:.2%}, {sol_metrics['rate_hdi'][1]:.2%}]\\n\\n\")\n",
        "\n",
        "        panel_content.append(f\"Abs. Diff ({sol_metrics['name']} - Control):\\n\", style=\"bold dark_violet\")\n",
        "        panel_content.append(f\"  Mean: {sol_metrics['absolute_difference_mean']:.2%}, 95% HDI: [{sol_metrics['absolute_difference_hdi'][0]:.2%}, {sol_metrics['absolute_difference_hdi'][1]:.2%}]\\n\")\n",
        "\n",
        "        rl_mean_val = sol_metrics.get('relative_lift_mean', np.nan)\n",
        "        rl_hdi_low_val, rl_hdi_high_val = sol_metrics.get('relative_lift_hdi', (np.nan, np.nan))\n",
        "        if not np.isnan(rl_mean_val):\n",
        "            panel_content.append(f\"Rel. Lift (({sol_metrics['name']}-Ctrl)/Ctrl):\\n\", style=\"bold green4\")\n",
        "            panel_content.append(f\"  Mean: {rl_mean_val:.2%}, 95% HDI: [{rl_hdi_low_val:.2%}, {rl_hdi_high_val:.2%}]\\n\\n\")\n",
        "        else:\n",
        "            panel_content.append(\"\\n\")\n",
        "\n",
        "\n",
        "    console.print(Panel(panel_content, title=\"[bold]Confidence Intervals (95% HDI)[/bold]\", border_style=\"steel_blue\", expand=False))\n",
        "\n",
        "\n",
        "def display_detailed_metrics(console, metrics, rope_abs_diff, rope_rel_lift):\n",
        "    panel_content = Text()\n",
        "\n",
        "    panel_content.append(\"Probability of Being Best Overall:\\n\", style=\"bold underline\")\n",
        "    panel_content.append(f\"  Control: {metrics.get('prob_control_is_best', 0.0):.2%}\\n\")\n",
        "    for sol_metrics in metrics['solutions']:\n",
        "        panel_content.append(f\"  {sol_metrics['name']}: {sol_metrics.get('prob_is_best', 0.0):.2%}\\n\")\n",
        "    panel_content.append(\"\\n\")\n",
        "\n",
        "    for i, sol_metrics in enumerate(metrics['solutions']):\n",
        "        panel_content.append(f\"--- Analysis for {sol_metrics['name']} vs Control ---\\n\", style=\"bold yellow\")\n",
        "        panel_content.append(\"Probabilities:\\n\", style=\"bold underline\")\n",
        "        panel_content.append(f\"  P({sol_metrics['name']} > Control): {sol_metrics['prob_beats_control']:.2%}\\n\")\n",
        "        panel_content.append(f\"  P({sol_metrics['name']} > Ctrl + {metrics.get('prob_beat_threshold_value',0.0):.1%}): {sol_metrics['prob_beats_control_by_threshold']:.2%}\\n\\n\")\n",
        "\n",
        "        panel_content.append(f\"ROPE Analysis (Absolute Difference: {rope_abs_diff[0]:.2%} to {rope_abs_diff[1]:.2%}):\\n\", style=\"bold underline\")\n",
        "        panel_content.append(f\"  P(Diff < ROPE Low): {sol_metrics['prob_abs_diff_below_rope']:.2%}\\n\")\n",
        "        panel_content.append(f\"  P(Diff In ROPE):   {sol_metrics['prob_abs_diff_in_rope']:.2%}\\n\")\n",
        "        panel_content.append(f\"  P(Diff > ROPE High):{sol_metrics['prob_abs_diff_above_rope']:.2%}\\n\\n\")\n",
        "\n",
        "        if not np.isnan(sol_metrics.get('prob_rel_lift_in_rope', np.nan)):\n",
        "            panel_content.append(f\"ROPE Analysis (Relative Lift: {rope_rel_lift[0]:.1%} to {rope_rel_lift[1]:.1%}):\\n\", style=\"bold underline\")\n",
        "            panel_content.append(f\"  P(Lift < ROPE Low): {sol_metrics.get('prob_rel_lift_below_rope', np.nan):.2%}\\n\")\n",
        "            panel_content.append(f\"  P(Lift In ROPE):   {sol_metrics.get('prob_rel_lift_in_rope', np.nan):.2%}\\n\")\n",
        "            panel_content.append(f\"  P(Lift > ROPE High):{sol_metrics.get('prob_rel_lift_above_rope', np.nan):.2%}\\n\\n\")\n",
        "\n",
        "        panel_content.append(f\"Expected Loss ({sol_metrics['name']} vs Control):\\n\", style=\"bold underline\")\n",
        "        panel_content.append(f\"  Choosing {sol_metrics['name']} (if Control is better): {sol_metrics['expected_loss_vs_control_choosing_solution']:.4%}\\n\")\n",
        "        panel_content.append(f\"  Choosing Control (if {sol_metrics['name']} is better): {sol_metrics['expected_loss_vs_control_choosing_control']:.4%}\\n\\n\")\n",
        "\n",
        "    console.print(Panel(panel_content, title=\"[bold]Further Analysis Details[/bold]\", border_style=\"green\", expand=False))\n",
        "\n",
        "def display_explanations(console):\n",
        "    text = Text()\n",
        "    text.append(\"Key Concepts:\\n\\n\", style=\"bold underline\")\n",
        "    text.append(\"ROPE (Region of Practical Equivalence):\\n\", style=\"bold cyan\")\n",
        "    text.append(\"  The range of differences you consider too small to matter. If the credible interval for the difference falls mostly within ROPE, the variants are practically equivalent.\\n\\n\")\n",
        "    text.append(\"HDI (Highest Density Interval):\\n\", style=\"bold cyan\")\n",
        "    text.append(\"  The range containing a specific percentage (e.g., 95%) of the most credible values for a parameter (e.g., conversion rate or difference). We can say there's a 95% probability the true value lies within the 95% HDI.\\n\\n\")\n",
        "\n",
        "    text.append(\"Interpreting 'Further Analysis Details':\\n\", style=\"bold underline\")\n",
        "    text.append(\"  - Probability of Being Best: For each variant, the chance it has the highest true conversion rate among all tested variants (including Control).\\n\")\n",
        "    text.append(\"  - Probabilities (vs Control): Shows the likelihood of a solution variant being better than Control, or better by a certain threshold.\\n\")\n",
        "    text.append(\"  - ROPE Analysis (vs Control): Shows the probability that the true difference/lift between a solution and Control falls below, within, or above your defined ROPE.\\n\")\n",
        "    text.append(\"  - Expected Loss (vs Control): Estimates the average 'cost' of making the wrong decision between a specific solution and Control.\\n\\n\")\n",
        "\n",
        "    text.append(\"Interpreting Charts:\\n\", style=\"bold underline\")\n",
        "    text.append(\"  - Prior plots show initial beliefs for Control and all Solutions, overlaid.\\n\")\n",
        "    text.append(\"  - Likelihood plots show what current test data suggests for each variant, overlaid.\\n\")\n",
        "    text.append(\"  - Posterior plots combine priors and likelihood for updated beliefs, overlaid. HDIs are marked as small shaded regions at the base.\\n\")\n",
        "    text.append(\"  - P(Best) Bar Chart: Visualizes the probability of each variant being the overall best.\\n\")\n",
        "    text.append(\"  - Difference plots show distributions of (Solution - Control) for the best solution or a selected one.\\n\")\n",
        "    text.append(\"  - Cumulative P(Uplift > X) plot shows the probability that the true relative uplift (for the best solution vs Control) is greater than X.\\n\")\n",
        "    text.append(\"  - Hover over chart elements for specific values.\\n\")\n",
        "    console.print(Panel(text, title=\"[bold]Understanding the Results[/bold]\", border_style=\"magenta\", expand=False))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Colab Form Inputs ---\n",
        "    # @title Bayesian A/B Test Analyzer Inputs\n",
        "    # @markdown ### General Setup\n",
        "    Number_of_Solution_Variants = 1 #@param {type:\"integer\", min:1, max:5, step:1}\n",
        "\n",
        "    # @markdown ---\n",
        "    # @markdown ### Control Group Priors (Beta Distribution: Î±, Î²)\n",
        "    # @markdown *Î±: prior 'successes' + 1, Î²: prior 'failures' + 1. Default (1,1) is uninformative.*\n",
        "    Control_Prior_Alpha_Successes = 1.0 #@param {type:\"number\"}\n",
        "    Control_Prior_Beta_Failures = 1.0 #@param {type:\"number\"}\n",
        "\n",
        "    # @markdown ---\n",
        "    # @markdown ### Solution Variant Priors\n",
        "    Auto_Generate_Solution_Priors = True #@param {type:\"boolean\"}\n",
        "    # @markdown *If auto-generating, specify total pseudo-observations for each solution prior (will use Control's prior rate). Enter one value (applied to all) or comma-separated values for each solution.*\n",
        "    Solution_Prior_Strength_Total_Observations_CSV = \"20\" #@param {type:\"string\"}\n",
        "    # @markdown *If NOT auto-generating, enter comma-separated Î± and Î² for each solution variant below.*\n",
        "    # @markdown *Example for 2 variants: `1.0,1.0` for alphas and `1.0,1.0` for betas.*\n",
        "    Manual_Solution_Prior_Alphas_CSV = \"\" #@param {type:\"string\"}\n",
        "    Manual_Solution_Prior_Betas_CSV = \"\" #@param {type:\"string\"}\n",
        "\n",
        "    # @markdown ---\n",
        "    # @markdown ### Test Results\n",
        "    # @markdown **Control Group:**\n",
        "    Control_Group_Samples = 1000 #@param {type:\"integer\"}\n",
        "    Control_Group_Conversions = 100 #@param {type:\"integer\"}\n",
        "    # @markdown **Solution Group(s):**\n",
        "    # @markdown *Enter comma-separated values if multiple solutions (e.g., `1000,1010` for samples).*\n",
        "    Solution_Samples_CSV = \"1000\" #@param {type:\"string\"}\n",
        "    Solution_Conversions_CSV = \"110\" #@param {type:\"string\"}\n",
        "\n",
        "    # @markdown ---\n",
        "    # @markdown ### ROPE (Region of Practical Equivalence)\n",
        "    # @markdown *Define a symmetrical relative lift ROPE (e.g., 2 for +/- 2%). Absolute ROPE will be derived.*\n",
        "    ROPE_Relative_Lift_Boundary_Percent = 2.0 #@param {type:\"number\"}\n",
        "    # @markdown *Minimum uplift threshold (decimal, e.g., 0.001 for 0.1%) for calculating P(Solution > Control + Threshold)*\n",
        "    Min_Uplift_Threshold_for_Prob_Calc_Decimal = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "    console = Console()\n",
        "    try:\n",
        "        # --- Process Form Inputs ---\n",
        "        num_solution_variants = int(Number_of_Solution_Variants)\n",
        "        control_prior_alpha = float(Control_Prior_Alpha_Successes)\n",
        "        control_prior_beta = float(Control_Prior_Beta_Failures)\n",
        "\n",
        "        solution_prior_alphas = []\n",
        "        solution_prior_betas = []\n",
        "\n",
        "        if Auto_Generate_Solution_Priors:\n",
        "            try:\n",
        "                solution_total_ns_list = [int(n.strip()) for n in Solution_Prior_Strength_Total_Observations_CSV.split(',')]\n",
        "                if len(solution_total_ns_list) == 1 and num_solution_variants > 1:\n",
        "                    solution_total_ns_list = [solution_total_ns_list[0]] * num_solution_variants\n",
        "                elif len(solution_total_ns_list) != num_solution_variants:\n",
        "                    raise ValueError(f\"Number of pseudo-observation Ns ({len(solution_total_ns_list)}) must match number of solution variants ({num_solution_variants}) or be 1.\")\n",
        "            except ValueError:\n",
        "                 raise ValueError(\"Invalid format for 'Total pseudo-observations for Solution prior'. Use comma-separated integers (e.g., 20 or 20,22).\")\n",
        "\n",
        "            for i in range(num_solution_variants):\n",
        "                solution_prior_total_n = solution_total_ns_list[i]\n",
        "                if solution_prior_total_n < 2: raise ValueError(\"Total pseudo-observations for solution prior must be at least 2.\")\n",
        "                if control_prior_alpha + control_prior_beta == 0:\n",
        "                    s_alpha, s_beta = 1.0, 1.0\n",
        "                else:\n",
        "                    control_prior_rate = control_prior_alpha / (control_prior_alpha + control_prior_beta)\n",
        "                    s_alpha_candidate = control_prior_rate * solution_prior_total_n\n",
        "                    s_beta_candidate = (1 - control_prior_rate) * solution_prior_total_n\n",
        "                    if s_alpha_candidate < 1.0: s_alpha = 1.0; s_beta = float(max(1.0, solution_prior_total_n - 1.0))\n",
        "                    elif s_beta_candidate < 1.0: s_beta = 1.0; s_alpha = float(max(1.0, solution_prior_total_n - 1.0))\n",
        "                    else: s_alpha = s_alpha_candidate; s_beta = s_beta_candidate\n",
        "                    if s_alpha < 1.0: s_alpha = 1.0\n",
        "                    if s_beta < 1.0: s_beta = 1.0\n",
        "                    current_sum = s_alpha + s_beta\n",
        "                    if not np.isclose(current_sum, solution_prior_total_n):\n",
        "                        if current_sum < solution_prior_total_n:\n",
        "                            if s_alpha >= s_beta: s_alpha += (solution_prior_total_n - current_sum)\n",
        "                            else: s_beta += (solution_prior_total_n - current_sum)\n",
        "                        else:\n",
        "                            if s_alpha >= s_beta: s_alpha -= (current_sum - solution_prior_total_n)\n",
        "                            else: s_beta -= (current_sum - solution_prior_total_n)\n",
        "                            if s_alpha < 1.0: s_beta -= (1.0-s_alpha); s_alpha=1.0\n",
        "                            if s_beta < 1.0: s_alpha -= (1.0-s_beta); s_beta=1.0\n",
        "                solution_prior_alphas.append(s_alpha)\n",
        "                solution_prior_betas.append(s_beta)\n",
        "        else:\n",
        "            try:\n",
        "                solution_prior_alphas = [float(x.strip()) for x in Manual_Solution_Prior_Alphas_CSV.split(',')]\n",
        "                solution_prior_betas = [float(x.strip()) for x in Manual_Solution_Prior_Betas_CSV.split(',')]\n",
        "                if len(solution_prior_alphas) != num_solution_variants or len(solution_prior_betas) != num_solution_variants:\n",
        "                    raise ValueError(\"Number of manual solution alphas/betas must match number of solution variants.\")\n",
        "            except ValueError:\n",
        "                raise ValueError(\"Invalid format for manual solution priors. Use comma-separated numbers (e.g., 1.0,1.5).\")\n",
        "\n",
        "        control_samples = int(Control_Group_Samples)\n",
        "        control_conversions = int(Control_Group_Conversions)\n",
        "        try:\n",
        "            solution_samples_list = [int(s.strip()) for s in Solution_Samples_CSV.split(',')]\n",
        "            solution_conversions_list = [int(c.strip()) for c in Solution_Conversions_CSV.split(',')]\n",
        "            if len(solution_samples_list) != num_solution_variants or len(solution_conversions_list) != num_solution_variants:\n",
        "                raise ValueError(\"Number of solution samples/conversions entries must match number of solution variants.\")\n",
        "        except ValueError:\n",
        "            raise ValueError(\"Invalid format for solution samples/conversions. Use comma-separated integers.\")\n",
        "\n",
        "        rope_rel_lift_upper = float(ROPE_Relative_Lift_Boundary_Percent) / 100.0\n",
        "        rope_rel_lift_lower = -rope_rel_lift_upper\n",
        "        rope_rel_lift = (rope_rel_lift_lower, rope_rel_lift_upper)\n",
        "\n",
        "        rope_abs_diff_lower = None; rope_abs_diff_high = None\n",
        "        if control_samples > 0 and control_samples >= control_conversions :\n",
        "            control_observed_rate = control_conversions / control_samples\n",
        "            if control_observed_rate > 1e-9:\n",
        "                abs_delta = rope_rel_lift_upper * control_observed_rate\n",
        "                rope_abs_diff_lower = -abs_delta; rope_abs_diff_high = abs_delta\n",
        "            else: console.print(f\"[yellow]Control observed rate is 0. Cannot derive absolute ROPE from relative ROPE. Using default.[/yellow]\")\n",
        "        else: console.print(f\"[yellow]Control samples are 0. Cannot derive absolute ROPE from relative ROPE. Using default.[/yellow]\")\n",
        "\n",
        "        if rope_abs_diff_lower is None or rope_abs_diff_high is None:\n",
        "            default_abs_rope_delta = 0.001\n",
        "            rope_abs_diff_lower = -default_abs_rope_delta; rope_abs_diff_high = default_abs_rope_delta\n",
        "            console.print(f\"[dim]Default Absolute Difference ROPE set to: ({rope_abs_diff_lower:.3%}, {rope_abs_diff_high:.3%})[/dim]\")\n",
        "        rope_abs_diff = (rope_abs_diff_lower, rope_abs_diff_high)\n",
        "\n",
        "        prob_beat_threshold = float(Min_Uplift_Threshold_for_Prob_Calc_Decimal)\n",
        "\n",
        "        # --- End of Form Input Processing ---\n",
        "\n",
        "        experiment = BayesianExperiment(num_solution_variants=num_solution_variants)\n",
        "        experiment.set_priors(\n",
        "            control_prior_alpha, control_prior_beta,\n",
        "            solution_prior_alphas, solution_prior_betas\n",
        "        )\n",
        "        experiment.update_results(\n",
        "            control_samples, control_conversions,\n",
        "            solution_samples_list, solution_conversions_list\n",
        "        )\n",
        "\n",
        "        console.print(\"\\n[bold]Calculating metrics...[/bold]\\n\")\n",
        "        metrics = experiment.calculate_metrics(\n",
        "            rope_abs_diff=rope_abs_diff,\n",
        "            rope_rel_lift=rope_rel_lift,\n",
        "            prob_beat_threshold=prob_beat_threshold\n",
        "        )\n",
        "        metrics['prob_beat_threshold_value'] = prob_beat_threshold\n",
        "\n",
        "        evaluation, recommendation, rec_style = experiment.get_decision_summary(\n",
        "            metrics, rope_abs_diff, p_threshold=0.95, loss_ratio_threshold=5\n",
        "        )\n",
        "        summary_panel_text = Text()\n",
        "        summary_panel_text.append(\"Evaluation: \", style=\"bold\")\n",
        "        summary_panel_text.append(f\"{evaluation}\\n\", style=f\"bold {rec_style}\")\n",
        "        summary_panel_text.append(\"Recommendation: \", style=\"bold\")\n",
        "        summary_panel_text.append(f\"{recommendation}\", style=f\"bold {rec_style}\")\n",
        "        console.print(Panel(summary_panel_text, title=\"[bold blue]Decision Summary[/bold blue]\", expand=False, border_style=rec_style))\n",
        "\n",
        "        display_test_outcomes_table(console, metrics)\n",
        "        display_confidence_intervals_summary(console, metrics)\n",
        "        display_detailed_metrics(console, metrics, rope_abs_diff, rope_rel_lift)\n",
        "\n",
        "        console.print(Panel(Text(\"Visualizations\", justify=\"center\"), title=\"[bold]Charts[/bold]\", border_style=\"yellow\", expand=False))\n",
        "        experiment.plot_distributions_plotly(\n",
        "            rope_abs_diff=rope_abs_diff,\n",
        "            rope_rel_lift=rope_rel_lift\n",
        "        )\n",
        "\n",
        "        display_explanations(console)\n",
        "        console.print(\"\\n[bold green]Analysis Complete.[/bold green]\")\n",
        "\n",
        "    except ValueError as ve:\n",
        "        console.print(f\"[bold red]Input Error:[/bold red] {ve}\")\n",
        "    except Exception as e:\n",
        "        console.print(f\"[bold red]An unexpected error occurred:[/bold red] {e}\")\n",
        "        import traceback\n",
        "        console.print(traceback.format_exc())\n",
        "\n",
        "\n",
        "# --- Display Helper Functions --- (No changes from previous version)\n",
        "def display_test_outcomes_table(console, metrics):\n",
        "    \"\"\"Displays the Test Outcomes table for multiple variants.\"\"\"\n",
        "    table = Table(title=\"Test Outcomes Summary\", title_style=\"bold magenta\", border_style=\"blue\")\n",
        "    table.add_column(\"Group\", style=\"cyan\")\n",
        "    table.add_column(\"Win Rate (Mean)\", style=\"dim\")\n",
        "    table.add_column(\"Rel. Lift vs Ctrl (Mean)\", style=\"dim\")\n",
        "    table.add_column(\"95% HDI (Rate)\", style=\"dim\")\n",
        "\n",
        "    # Control Row\n",
        "    c_metrics = metrics['control']\n",
        "    table.add_row(\"Control\", f\"{c_metrics['posterior_mean_rate']:.2%}\", \"N/A\", f\"[{c_metrics['rate_hdi'][0]:.2%}, {c_metrics['rate_hdi'][1]:.2%}]\")\n",
        "\n",
        "    # Solution Variant Rows\n",
        "    for sol_metrics in metrics['solutions']:\n",
        "        rl_mean = sol_metrics.get('relative_lift_mean', np.nan)\n",
        "        table.add_row(\n",
        "            sol_metrics['name'],\n",
        "            f\"{sol_metrics['posterior_mean_rate']:.2%}\",\n",
        "            f\"{rl_mean:+.2%}\" if not np.isnan(rl_mean) else \"N/A\",\n",
        "            f\"[{sol_metrics['rate_hdi'][0]:.2%}, {sol_metrics['rate_hdi'][1]:.2%}]\"\n",
        "        )\n",
        "    console.print(Padding(table, (1, 0)))\n",
        "\n",
        "\n",
        "def display_confidence_intervals_summary(console, metrics):\n",
        "    \"\"\"Displays a dedicated summary of key confidence intervals for multiple variants.\"\"\"\n",
        "    panel_content = Text()\n",
        "    # Control\n",
        "    c_metrics = metrics['control']\n",
        "    panel_content.append(\"Control Conversion Rate:\\n\", style=\"bold sky_blue3\")\n",
        "    panel_content.append(f\"  Mean: {c_metrics['posterior_mean_rate']:.2%}, 95% HDI: [{c_metrics['rate_hdi'][0]:.2%}, {c_metrics['rate_hdi'][1]:.2%}]\\n\\n\")\n",
        "\n",
        "    # Solution Variants\n",
        "    for sol_metrics in metrics['solutions']:\n",
        "        panel_content.append(f\"{sol_metrics['name']} Conversion Rate:\\n\", style=\"bold light_coral\")\n",
        "        panel_content.append(f\"  Mean: {sol_metrics['posterior_mean_rate']:.2%}, 95% HDI: [{sol_metrics['rate_hdi'][0]:.2%}, {sol_metrics['rate_hdi'][1]:.2%}]\\n\\n\")\n",
        "\n",
        "        panel_content.append(f\"Abs. Diff ({sol_metrics['name']} - Control):\\n\", style=\"bold dark_violet\")\n",
        "        panel_content.append(f\"  Mean: {sol_metrics['absolute_difference_mean']:.2%}, 95% HDI: [{sol_metrics['absolute_difference_hdi'][0]:.2%}, {sol_metrics['absolute_difference_hdi'][1]:.2%}]\\n\")\n",
        "\n",
        "        rl_mean_val = sol_metrics.get('relative_lift_mean', np.nan)\n",
        "        rl_hdi_low_val, rl_hdi_high_val = sol_metrics.get('relative_lift_hdi', (np.nan, np.nan))\n",
        "        if not np.isnan(rl_mean_val):\n",
        "            panel_content.append(f\"Rel. Lift (({sol_metrics['name']}-Ctrl)/Ctrl):\\n\", style=\"bold green4\")\n",
        "            panel_content.append(f\"  Mean: {rl_mean_val:.2%}, 95% HDI: [{rl_hdi_low_val:.2%}, {rl_hdi_high_val:.2%}]\\n\\n\")\n",
        "        else:\n",
        "            panel_content.append(\"\\n\")\n",
        "\n",
        "\n",
        "    console.print(Panel(panel_content, title=\"[bold]Confidence Intervals (95% HDI)[/bold]\", border_style=\"steel_blue\", expand=False))\n",
        "\n",
        "\n",
        "def display_detailed_metrics(console, metrics, rope_abs_diff, rope_rel_lift):\n",
        "    panel_content = Text()\n",
        "\n",
        "    panel_content.append(\"Probability of Being Best Overall:\\n\", style=\"bold underline\")\n",
        "    panel_content.append(f\"  Control: {metrics.get('prob_control_is_best', 0.0):.2%}\\n\")\n",
        "    for sol_metrics in metrics['solutions']:\n",
        "        panel_content.append(f\"  {sol_metrics['name']}: {sol_metrics.get('prob_is_best', 0.0):.2%}\\n\")\n",
        "    panel_content.append(\"\\n\")\n",
        "\n",
        "    for i, sol_metrics in enumerate(metrics['solutions']):\n",
        "        panel_content.append(f\"--- Analysis for {sol_metrics['name']} vs Control ---\\n\", style=\"bold yellow\")\n",
        "        panel_content.append(\"Probabilities:\\n\", style=\"bold underline\")\n",
        "        panel_content.append(f\"  P({sol_metrics['name']} > Control): {sol_metrics['prob_beats_control']:.2%}\\n\")\n",
        "        panel_content.append(f\"  P({sol_metrics['name']} > Ctrl + {metrics.get('prob_beat_threshold_value',0.0):.1%}): {sol_metrics['prob_beats_control_by_threshold']:.2%}\\n\\n\")\n",
        "\n",
        "        panel_content.append(f\"ROPE Analysis (Absolute Difference: {rope_abs_diff[0]:.2%} to {rope_abs_diff[1]:.2%}):\\n\", style=\"bold underline\")\n",
        "        panel_content.append(f\"  P(Diff < ROPE Low): {sol_metrics['prob_abs_diff_below_rope']:.2%}\\n\")\n",
        "        panel_content.append(f\"  P(Diff In ROPE):   {sol_metrics['prob_abs_diff_in_rope']:.2%}\\n\")\n",
        "        panel_content.append(f\"  P(Diff > ROPE High):{sol_metrics['prob_abs_diff_above_rope']:.2%}\\n\\n\")\n",
        "\n",
        "        if not np.isnan(sol_metrics.get('prob_rel_lift_in_rope', np.nan)):\n",
        "            panel_content.append(f\"ROPE Analysis (Relative Lift: {rope_rel_lift[0]:.1%} to {rope_rel_lift[1]:.1%}):\\n\", style=\"bold underline\")\n",
        "            panel_content.append(f\"  P(Lift < ROPE Low): {sol_metrics.get('prob_rel_lift_below_rope', np.nan):.2%}\\n\")\n",
        "            panel_content.append(f\"  P(Lift In ROPE):   {sol_metrics.get('prob_rel_lift_in_rope', np.nan):.2%}\\n\")\n",
        "            panel_content.append(f\"  P(Lift > ROPE High):{sol_metrics.get('prob_rel_lift_above_rope', np.nan):.2%}\\n\\n\")\n",
        "\n",
        "        panel_content.append(f\"Expected Loss ({sol_metrics['name']} vs Control):\\n\", style=\"bold underline\")\n",
        "        panel_content.append(f\"  Choosing {sol_metrics['name']} (if Control is better): {sol_metrics['expected_loss_vs_control_choosing_solution']:.4%}\\n\")\n",
        "        panel_content.append(f\"  Choosing Control (if {sol_metrics['name']} is better): {sol_metrics['expected_loss_vs_control_choosing_control']:.4%}\\n\\n\")\n",
        "\n",
        "    console.print(Panel(panel_content, title=\"[bold]Further Analysis Details[/bold]\", border_style=\"green\", expand=False))\n",
        "\n",
        "def display_explanations(console):\n",
        "    text = Text()\n",
        "    text.append(\"Key Concepts:\\n\\n\", style=\"bold underline\")\n",
        "    text.append(\"ROPE (Region of Practical Equivalence):\\n\", style=\"bold cyan\")\n",
        "    text.append(\"  The range of differences you consider too small to matter. If the credible interval for the difference falls mostly within ROPE, the variants are practically equivalent.\\n\\n\")\n",
        "    text.append(\"HDI (Highest Density Interval):\\n\", style=\"bold cyan\")\n",
        "    text.append(\"  The range containing a specific percentage (e.g., 95%) of the most credible values for a parameter (e.g., conversion rate or difference). We can say there's a 95% probability the true value lies within the 95% HDI.\\n\\n\")\n",
        "\n",
        "    text.append(\"Interpreting 'Further Analysis Details':\\n\", style=\"bold underline\")\n",
        "    text.append(\"  - Probability of Being Best: For each variant, the chance it has the highest true conversion rate among all tested variants (including Control).\\n\")\n",
        "    text.append(\"  - Probabilities (vs Control): Shows the likelihood of a solution variant being better than Control, or better by a certain threshold.\\n\")\n",
        "    text.append(\"  - ROPE Analysis (vs Control): Shows the probability that the true difference/lift between a solution and Control falls below, within, or above your defined ROPE.\\n\")\n",
        "    text.append(\"  - Expected Loss (vs Control): Estimates the average 'cost' of making the wrong decision between a specific solution and Control.\\n\\n\")\n",
        "\n",
        "    text.append(\"Interpreting Charts:\\n\", style=\"bold underline\")\n",
        "    text.append(\"  - Prior plots show initial beliefs for Control and all Solutions, overlaid.\\n\")\n",
        "    text.append(\"  - Likelihood plots show what current test data suggests for each variant, overlaid.\\n\")\n",
        "    text.append(\"  - Posterior plots combine priors and likelihood for updated beliefs, overlaid. HDIs are marked as small shaded regions at the base.\\n\")\n",
        "    text.append(\"  - P(Best) Bar Chart: Visualizes the probability of each variant being the overall best.\\n\")\n",
        "    text.append(\"  - Difference plots show distributions of (Solution - Control) for the best solution or a selected one.\\n\")\n",
        "    text.append(\"  - Cumulative P(Uplift > X) plot shows the probability that the true relative uplift (for the best solution vs Control) is greater than X.\\n\")\n",
        "    text.append(\"  - Hover over chart elements for specific values.\\n\")\n",
        "    console.print(Panel(text, title=\"[bold]Understanding the Results[/bold]\", border_style=\"magenta\", expand=False))\n"
      ],
      "metadata": {
        "id": "sDoAHNm6Hy9o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}